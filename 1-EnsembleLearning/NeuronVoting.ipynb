{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPSy3VPHL5Uq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import deeplake\n",
    "from time import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V2SCe0hDNeaV",
    "outputId": "02ea31cc-a3e8-4b9e-da02-1f2821ca4e52"
   },
   "outputs": [],
   "source": [
    "def LoadData(DATA, batch_size):\n",
    "\n",
    "    if DATA == \"CIFAR10\":\n",
    "        root = '../Data/CIFAR10'\n",
    "        num_classes = 10\n",
    "\n",
    "        cifar10_train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        cifar10_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "        train = torchvision.datasets.CIFAR10(root=root, train=True, transform=cifar10_train_transform)\n",
    "        test = torchvision.datasets.CIFAR10(root=root, train=False, transform=cifar10_test_transform)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"CIFAR100\":\n",
    "        root = '../Data/CIFAR100'\n",
    "        num_classes = 100\n",
    "\n",
    "        cifar100_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(32, scale=(0.8, 1.2)), # Simulate scale variations\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=15), # Consider for object orientations\n",
    "            transforms.RandomGrayscale(p=0.2), # Optional for color augmentation\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Standard CIFAR-100 normalization\n",
    "        ])\n",
    "        cifar100_test_transform = transforms.Compose([\n",
    "            # transforms.Resize(32),\n",
    "            # transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.CIFAR100(root=root, train=True, transform=cifar100_train_transform)\n",
    "        test = torchvision.datasets.CIFAR100(root=root, train=False, transform=cifar100_test_transform)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"IMAGENET\":\n",
    "        root = '../Data/IMAGENET'\n",
    "        num_classes = 200\n",
    "\n",
    "        tiny_imagenet_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(64, scale=(0.8, 1.2), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        tiny_imagenet_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "\n",
    "        train = deeplake.load(\"hub://activeloop/tiny-imagenet-train\")\n",
    "        test = deeplake.load(\"hub://activeloop/tiny-imagenet-test\")\n",
    "\n",
    "        train.pytorch(transform = tiny_imagenet_train_transform, batch_size = batch_size, shuffle = True)\n",
    "        test.pytorch(transform = tiny_imagenet_test_transform, batch_size = batch_size, shuffle = False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"MNIST\":\n",
    "        root='../Data/MNIST'\n",
    "        num_classes = 10\n",
    "\n",
    "        mnist_train_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(10),  # Improve robustness\n",
    "            transforms.RandomHorizontalFlip(),  # Augment data\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "\n",
    "        mnist_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.MNIST(root=root, train=True, transform=mnist_train_transform, download=True)\n",
    "        test = torchvision.datasets.MNIST(root=root, train=False, transform=mnist_test_transform ,download=True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"FASION_MNIST\":\n",
    "        root='../Data/FASION_MNIST'\n",
    "        num_classes = 10\n",
    "\n",
    "        fashion_mnist_train_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(15),  # Improve robustness\n",
    "            transforms.RandomHorizontalFlip(),  # Augment data\n",
    "            transforms.RandomResizedCrop(28),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        fashion_mnist_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.FashionMNIST(root=root, train=True, transform=fashion_mnist_train_transform, download=True)\n",
    "        test = torchvision.datasets.FashionMNIST(root=root, train=False, transform=fashion_mnist_test_transform ,download=True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"PascalVOC\":\n",
    "        root = '../Data/PascalVOC'\n",
    "        num_classes = 20\n",
    "\n",
    "        voc_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
    "            transforms.RandomHorizontalFlip(),  # Randomly flip for horizontal invariance\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        voc_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.VOCDetection(root=root, year='2012', image_set='trainval', transform=voc_train_transform, download = True)\n",
    "        test = torchvision.datasets.VOCDetection(root=root, year='2012', image_set='trainval', transform=voc_test_transform, download = True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"Flowers102\":\n",
    "        root = '../Data/Flowers102'\n",
    "        num_classes = 102\n",
    "\n",
    "        oxford102_train_transform = transforms.Compose([\n",
    "            transforms.Resize(256),  # Adjust size based on your model\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),  # Simulate scale variations\n",
    "            transforms.RandomHorizontalFlip(),  # Increase data diversity\n",
    "            transforms.RandomRotation(15),  # Consider for specific flower orientations (optional)\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Introduce color variations\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  # ImageNet stats, adjust if needed\n",
    "        ])\n",
    "\n",
    "\n",
    "        oxford102_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "\n",
    "        train = torchvision.datasets.Flowers102(root=root, transform=oxford102_train_transform, download=True)\n",
    "        test = torchvision.datasets.Flowers102(root=root, transform=oxford102_test_transform, download = True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    return trainloader, testloader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVrCGU9jNkJb"
   },
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1a = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1a = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2a = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2a = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3a = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3a = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "        self.conv1b = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1b = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2b = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2b = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3b = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3b = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x.clone()\n",
    "        xa = self.relu(self.batch_norm1a(self.conv1a(x)))\n",
    "        xb = self.relu(self.batch_norm1b(self.conv1b(x)))\n",
    "        x = (xa + xb)/2\n",
    "\n",
    "        xa = self.relu(self.batch_norm2a(self.conv2a(x)))\n",
    "        xb = self.relu(self.batch_norm2b(self.conv2b(x)))\n",
    "        x = (xa + xb)/2\n",
    "\n",
    "        xa = self.batch_norm3a(self.conv3a(x))\n",
    "        xb = self.batch_norm3b(self.conv3b(x))\n",
    "        x = (xa + xb)/2\n",
    "\n",
    "\n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "\n",
    "        global L\n",
    "        L = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "\n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer):\n",
    "    total = 0.\n",
    "    correct = 0.\n",
    "    running_loss = 0.\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_loss = running_loss / total\n",
    "\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, criterion):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_loss = running_loss / total\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASION_MNIST successfully loaded.\n",
      "{'Epoch': 1, 'Train Loss': 0.022883301585912705, 'Train Accuracy': 28.538333333333334, 'Train Time': 51.24291801452637, 'Test Loss': 0.013135300672054291, 'Test Accuracy': 44.92, 'Test Time': 2.5609357357025146}\n",
      "{'Epoch': 2, 'Train Loss': 0.0116845835963885, 'Train Accuracy': 45.78333333333333, 'Train Time': 51.87430667877197, 'Test Loss': 0.008811511939764023, 'Test Accuracy': 59.32, 'Test Time': 2.6332590579986572}\n",
      "{'Epoch': 3, 'Train Loss': 0.009630450886487962, 'Train Accuracy': 53.973333333333336, 'Train Time': 51.92314839363098, 'Test Loss': 0.006675234204530716, 'Test Accuracy': 67.58, 'Test Time': 2.5449891090393066}\n",
      "{'Epoch': 4, 'Train Loss': 0.008775096066792805, 'Train Accuracy': 57.65, 'Train Time': 51.80410695075989, 'Test Loss': 0.005599162495136261, 'Test Accuracy': 72.73, 'Test Time': 2.5983755588531494}\n",
      "{'Epoch': 5, 'Train Loss': 0.008171857155362765, 'Train Accuracy': 60.79666666666667, 'Train Time': 52.20203351974487, 'Test Loss': 0.005191274297237396, 'Test Accuracy': 75.69, 'Test Time': 2.5856306552886963}\n",
      "{'Epoch': 6, 'Train Loss': 0.007822626935442289, 'Train Accuracy': 62.8, 'Train Time': 52.00031518936157, 'Test Loss': 0.0050049967557191846, 'Test Accuracy': 76.24, 'Test Time': 2.5951552391052246}\n",
      "{'Epoch': 7, 'Train Loss': 0.007498429540793101, 'Train Accuracy': 64.61333333333333, 'Train Time': 51.919315338134766, 'Test Loss': 0.004906150376796722, 'Test Accuracy': 77.31, 'Test Time': 2.5609235763549805}\n",
      "{'Epoch': 8, 'Train Loss': 0.007258711875478427, 'Train Accuracy': 65.78, 'Train Time': 51.735265493392944, 'Test Loss': 0.004467509815096855, 'Test Accuracy': 79.37, 'Test Time': 2.6241486072540283}\n",
      "{'Epoch': 9, 'Train Loss': 0.007064413221677144, 'Train Accuracy': 66.78166666666667, 'Train Time': 51.673954486846924, 'Test Loss': 0.004187325203418732, 'Test Accuracy': 80.45, 'Test Time': 2.5786290168762207}\n",
      "{'Epoch': 10, 'Train Loss': 0.006906839661796888, 'Train Accuracy': 67.40333333333334, 'Train Time': 51.92995738983154, 'Test Loss': 0.004348681163787842, 'Test Accuracy': 79.91, 'Test Time': 2.5945627689361572}\n",
      "{'Epoch': 11, 'Train Loss': 0.006698420754075051, 'Train Accuracy': 68.60333333333334, 'Train Time': 52.30613112449646, 'Test Loss': 0.003760939460992813, 'Test Accuracy': 82.12, 'Test Time': 2.6243038177490234}\n",
      "{'Epoch': 12, 'Train Loss': 0.006578475677967072, 'Train Accuracy': 69.16, 'Train Time': 52.36768388748169, 'Test Loss': 0.0038957919523119927, 'Test Accuracy': 81.25, 'Test Time': 2.6713788509368896}\n",
      "{'Epoch': 13, 'Train Loss': 0.006431837341189384, 'Train Accuracy': 69.68166666666667, 'Train Time': 51.428030490875244, 'Test Loss': 0.003977273055911064, 'Test Accuracy': 81.46, 'Test Time': 2.612482786178589}\n",
      "{'Epoch': 14, 'Train Loss': 0.006320217728614807, 'Train Accuracy': 70.16333333333333, 'Train Time': 51.842068910598755, 'Test Loss': 0.0034719579339027406, 'Test Accuracy': 84.06, 'Test Time': 2.6237969398498535}\n",
      "{'Epoch': 15, 'Train Loss': 0.006223385148247083, 'Train Accuracy': 70.435, 'Train Time': 51.804930686950684, 'Test Loss': 0.004154709389805794, 'Test Accuracy': 78.85, 'Test Time': 2.6648597717285156}\n",
      "{'Epoch': 16, 'Train Loss': 0.006121135450402895, 'Train Accuracy': 71.295, 'Train Time': 51.72477841377258, 'Test Loss': 0.003816608762741089, 'Test Accuracy': 82.22, 'Test Time': 2.5958731174468994}\n",
      "{'Epoch': 17, 'Train Loss': 0.0060300716464718185, 'Train Accuracy': 71.50666666666666, 'Train Time': 51.49391293525696, 'Test Loss': 0.004017874029278755, 'Test Accuracy': 81.1, 'Test Time': 2.619978904724121}\n",
      "{'Epoch': 18, 'Train Loss': 0.005950390087564786, 'Train Accuracy': 72.17666666666666, 'Train Time': 52.4801664352417, 'Test Loss': 0.0037065174907445907, 'Test Accuracy': 83.26, 'Test Time': 2.614732265472412}\n",
      "{'Epoch': 19, 'Train Loss': 0.0058352497667074205, 'Train Accuracy': 72.44666666666667, 'Train Time': 51.99216890335083, 'Test Loss': 0.0034175148218870163, 'Test Accuracy': 84.1, 'Test Time': 2.6370646953582764}\n",
      "{'Epoch': 20, 'Train Loss': 0.005859313292304675, 'Train Accuracy': 72.60333333333334, 'Train Time': 51.930596351623535, 'Test Loss': 0.0033826487600803375, 'Test Accuracy': 84.22, 'Test Time': 2.5788958072662354}\n",
      "{'Epoch': 21, 'Train Loss': 0.005718155764540036, 'Train Accuracy': 73.075, 'Train Time': 51.71152138710022, 'Test Loss': 0.0034299212723970414, 'Test Accuracy': 84.4, 'Test Time': 2.621307373046875}\n",
      "{'Epoch': 22, 'Train Loss': 0.005755639295776685, 'Train Accuracy': 72.96666666666667, 'Train Time': 51.77010154724121, 'Test Loss': 0.0034482445508241654, 'Test Accuracy': 84.22, 'Test Time': 2.5814192295074463}\n",
      "{'Epoch': 23, 'Train Loss': 0.005657660926381747, 'Train Accuracy': 73.43833333333333, 'Train Time': 51.86755704879761, 'Test Loss': 0.0034085024520754815, 'Test Accuracy': 83.76, 'Test Time': 2.6478655338287354}\n",
      "{'Epoch': 24, 'Train Loss': 0.005574990839759509, 'Train Accuracy': 73.80833333333334, 'Train Time': 52.01611542701721, 'Test Loss': 0.0037406378388404847, 'Test Accuracy': 82.95, 'Test Time': 2.635657548904419}\n",
      "{'Epoch': 25, 'Train Loss': 0.005548368602991104, 'Train Accuracy': 73.76666666666667, 'Train Time': 52.10316753387451, 'Test Loss': 0.003577446725964546, 'Test Accuracy': 84.25, 'Test Time': 2.6579174995422363}\n",
      "{'Epoch': 26, 'Train Loss': 0.005467471097409725, 'Train Accuracy': 74.17833333333333, 'Train Time': 56.273887634277344, 'Test Loss': 0.00377772730588913, 'Test Accuracy': 83.14, 'Test Time': 3.659646987915039}\n",
      "{'Epoch': 27, 'Train Loss': 0.005459306932489077, 'Train Accuracy': 74.33166666666666, 'Train Time': 79.13742327690125, 'Test Loss': 0.004002115425467491, 'Test Accuracy': 81.15, 'Test Time': 4.725379467010498}\n",
      "{'Epoch': 28, 'Train Loss': 0.00537877371609211, 'Train Accuracy': 74.63833333333334, 'Train Time': 81.12312698364258, 'Test Loss': 0.0033049009084701536, 'Test Accuracy': 84.4, 'Test Time': 4.600950241088867}\n",
      "{'Epoch': 29, 'Train Loss': 0.005380686916907629, 'Train Accuracy': 74.64333333333333, 'Train Time': 81.12842607498169, 'Test Loss': 0.0031020711824297905, 'Test Accuracy': 85.49, 'Test Time': 4.604081869125366}\n",
      "{'Epoch': 30, 'Train Loss': 0.005527685707310836, 'Train Accuracy': 73.97166666666666, 'Train Time': 81.24150800704956, 'Test Loss': 0.0036439258873462678, 'Test Accuracy': 81.86, 'Test Time': 4.581776857376099}\n",
      "{'Epoch': 31, 'Train Loss': 0.0054950006435314815, 'Train Accuracy': 74.29166666666667, 'Train Time': 80.82270073890686, 'Test Loss': 0.0032093517586588858, 'Test Accuracy': 85.07, 'Test Time': 4.559451580047607}\n",
      "{'Epoch': 32, 'Train Loss': 0.005307558323442936, 'Train Accuracy': 75.18, 'Train Time': 81.26393055915833, 'Test Loss': 0.003305129739642143, 'Test Accuracy': 83.77, 'Test Time': 4.580830812454224}\n",
      "{'Epoch': 33, 'Train Loss': 0.005280669317642848, 'Train Accuracy': 75.115, 'Train Time': 81.14275312423706, 'Test Loss': 0.0033777721390128137, 'Test Accuracy': 83.37, 'Test Time': 4.655238628387451}\n",
      "{'Epoch': 34, 'Train Loss': 0.005206799684961637, 'Train Accuracy': 75.37666666666667, 'Train Time': 80.90288710594177, 'Test Loss': 0.0030978136479854583, 'Test Accuracy': 85.58, 'Test Time': 4.627614974975586}\n",
      "{'Epoch': 35, 'Train Loss': 0.005229643395543098, 'Train Accuracy': 75.34666666666666, 'Train Time': 80.86583161354065, 'Test Loss': 0.003300043508410454, 'Test Accuracy': 85.16, 'Test Time': 4.6039347648620605}\n",
      "{'Epoch': 36, 'Train Loss': 0.005136887080470721, 'Train Accuracy': 75.83833333333334, 'Train Time': 81.19384217262268, 'Test Loss': 0.003116736151278019, 'Test Accuracy': 85.96, 'Test Time': 4.587306022644043}\n",
      "{'Epoch': 37, 'Train Loss': 0.005194179750482242, 'Train Accuracy': 75.61833333333334, 'Train Time': 81.10502672195435, 'Test Loss': 0.0029792927101254464, 'Test Accuracy': 85.95, 'Test Time': 4.598158836364746}\n",
      "{'Epoch': 38, 'Train Loss': 0.00559938960870107, 'Train Accuracy': 73.43833333333333, 'Train Time': 79.46628212928772, 'Test Loss': 0.0029728639379143717, 'Test Accuracy': 86.05, 'Test Time': 4.4997711181640625}\n",
      "{'Epoch': 39, 'Train Loss': 0.005195813125868638, 'Train Accuracy': 75.69833333333334, 'Train Time': 79.39209055900574, 'Test Loss': 0.003251617032289505, 'Test Accuracy': 84.18, 'Test Time': 4.487672567367554}\n",
      "{'Epoch': 40, 'Train Loss': 0.005096615318457285, 'Train Accuracy': 76.075, 'Train Time': 79.59697103500366, 'Test Loss': 0.002737075710296631, 'Test Accuracy': 86.88, 'Test Time': 4.595721960067749}\n",
      "{'Epoch': 41, 'Train Loss': 0.005040786850949128, 'Train Accuracy': 76.13333333333334, 'Train Time': 79.90969443321228, 'Test Loss': 0.002829913406074047, 'Test Accuracy': 86.58, 'Test Time': 4.574054002761841}\n",
      "{'Epoch': 42, 'Train Loss': 0.005014951910078526, 'Train Accuracy': 76.27166666666666, 'Train Time': 80.11325645446777, 'Test Loss': 0.0030695692136883737, 'Test Accuracy': 85.54, 'Test Time': 4.591681480407715}\n",
      "{'Epoch': 43, 'Train Loss': 0.005022237327694893, 'Train Accuracy': 76.21666666666667, 'Train Time': 79.43227124214172, 'Test Loss': 0.0036031764328479767, 'Test Accuracy': 83.38, 'Test Time': 4.5304179191589355}\n",
      "{'Epoch': 44, 'Train Loss': 0.004919461323817571, 'Train Accuracy': 76.82833333333333, 'Train Time': 79.48227190971375, 'Test Loss': 0.002870853263139725, 'Test Accuracy': 87.25, 'Test Time': 4.551359176635742}\n",
      "{'Epoch': 45, 'Train Loss': 0.004911451924343904, 'Train Accuracy': 76.93333333333334, 'Train Time': 79.85884261131287, 'Test Loss': 0.002955563759803772, 'Test Accuracy': 86.69, 'Test Time': 4.559183120727539}\n",
      "{'Epoch': 46, 'Train Loss': 0.004885992887616157, 'Train Accuracy': 76.925, 'Train Time': 80.46249842643738, 'Test Loss': 0.0031102892518043517, 'Test Accuracy': 85.09, 'Test Time': 4.5508763790130615}\n",
      "{'Epoch': 47, 'Train Loss': 0.004902399991949399, 'Train Accuracy': 76.825, 'Train Time': 79.62429070472717, 'Test Loss': 0.0030686485275626184, 'Test Accuracy': 85.14, 'Test Time': 4.53398323059082}\n",
      "{'Epoch': 48, 'Train Loss': 0.0048866210098067915, 'Train Accuracy': 77.09833333333333, 'Train Time': 79.16896677017212, 'Test Loss': 0.003432936027646065, 'Test Accuracy': 84.54, 'Test Time': 4.509278059005737}\n",
      "{'Epoch': 49, 'Train Loss': 0.00484230859130621, 'Train Accuracy': 77.16, 'Train Time': 79.6429226398468, 'Test Loss': 0.002787836779654026, 'Test Accuracy': 86.91, 'Test Time': 4.561898469924927}\n",
      "{'Epoch': 50, 'Train Loss': 0.004831562358637651, 'Train Accuracy': 77.06333333333333, 'Train Time': 79.97940325737, 'Test Loss': 0.0030828150153160093, 'Test Accuracy': 85.42, 'Test Time': 4.420518636703491}\n",
      "{'Epoch': 51, 'Train Loss': 0.004862269828220208, 'Train Accuracy': 76.975, 'Train Time': 60.26241874694824, 'Test Loss': 0.003032088030874729, 'Test Accuracy': 85.5, 'Test Time': 3.458247661590576}\n",
      "{'Epoch': 52, 'Train Loss': 0.004787377695739269, 'Train Accuracy': 77.46166666666667, 'Train Time': 59.49700093269348, 'Test Loss': 0.0027766768142580985, 'Test Accuracy': 86.42, 'Test Time': 3.419996738433838}\n",
      "{'Epoch': 53, 'Train Loss': 0.004818535888691743, 'Train Accuracy': 77.24, 'Train Time': 59.52631616592407, 'Test Loss': 0.002941359260678291, 'Test Accuracy': 86.03, 'Test Time': 3.4386425018310547}\n",
      "{'Epoch': 54, 'Train Loss': 0.004784448869526386, 'Train Accuracy': 77.52166666666666, 'Train Time': 59.8136830329895, 'Test Loss': 0.0026722927659749984, 'Test Accuracy': 87.71, 'Test Time': 3.3358569145202637}\n",
      "{'Epoch': 55, 'Train Loss': 0.00470300110677878, 'Train Accuracy': 77.875, 'Train Time': 60.09889626502991, 'Test Loss': 0.002715709063410759, 'Test Accuracy': 87.48, 'Test Time': 3.449826240539551}\n",
      "{'Epoch': 56, 'Train Loss': 0.004750584953526656, 'Train Accuracy': 77.85833333333333, 'Train Time': 60.11302185058594, 'Test Loss': 0.0030485826954245567, 'Test Accuracy': 85.53, 'Test Time': 3.4317803382873535}\n",
      "{'Epoch': 57, 'Train Loss': 0.004725136256714662, 'Train Accuracy': 77.71833333333333, 'Train Time': 60.438257694244385, 'Test Loss': 0.002830010238289833, 'Test Accuracy': 86.64, 'Test Time': 3.419396162033081}\n",
      "{'Epoch': 58, 'Train Loss': 0.004705261364579201, 'Train Accuracy': 77.74166666666666, 'Train Time': 59.4544415473938, 'Test Loss': 0.0029940270513296127, 'Test Accuracy': 85.07, 'Test Time': 3.3875999450683594}\n",
      "{'Epoch': 59, 'Train Loss': 0.004696109818418821, 'Train Accuracy': 78.075, 'Train Time': 59.87673854827881, 'Test Loss': 0.0031388949066400527, 'Test Accuracy': 84.73, 'Test Time': 3.3737754821777344}\n",
      "{'Epoch': 60, 'Train Loss': 0.0047365863422552746, 'Train Accuracy': 77.455, 'Train Time': 60.30566382408142, 'Test Loss': 0.002781155462563038, 'Test Accuracy': 86.76, 'Test Time': 3.471752882003784}\n",
      "{'Epoch': 61, 'Train Loss': 0.004707947019735972, 'Train Accuracy': 77.69666666666667, 'Train Time': 59.996036529541016, 'Test Loss': 0.00318981511592865, 'Test Accuracy': 84.9, 'Test Time': 3.514381170272827}\n",
      "{'Epoch': 62, 'Train Loss': 0.0047205330967903135, 'Train Accuracy': 77.85833333333333, 'Train Time': 60.454933166503906, 'Test Loss': 0.0027556827560067175, 'Test Accuracy': 86.74, 'Test Time': 3.4981212615966797}\n",
      "{'Epoch': 63, 'Train Loss': 0.004667705732584, 'Train Accuracy': 78.03166666666667, 'Train Time': 59.91858696937561, 'Test Loss': 0.0027626669853925705, 'Test Accuracy': 87.2, 'Test Time': 3.4367833137512207}\n",
      "{'Epoch': 64, 'Train Loss': 0.004628942038615544, 'Train Accuracy': 78.215, 'Train Time': 59.6971321105957, 'Test Loss': 0.0034279544502496717, 'Test Accuracy': 83.93, 'Test Time': 3.415367364883423}\n",
      "{'Epoch': 65, 'Train Loss': 0.00461755557457606, 'Train Accuracy': 78.125, 'Train Time': 59.86578392982483, 'Test Loss': 0.00273451034873724, 'Test Accuracy': 87.48, 'Test Time': 3.4991869926452637}\n",
      "{'Epoch': 66, 'Train Loss': 0.004643181870381038, 'Train Accuracy': 78.13833333333334, 'Train Time': 59.48635125160217, 'Test Loss': 0.0026956361293792724, 'Test Accuracy': 87.71, 'Test Time': 3.458930253982544}\n",
      "{'Epoch': 67, 'Train Loss': 0.004609729589025179, 'Train Accuracy': 78.05333333333333, 'Train Time': 59.95143270492554, 'Test Loss': 0.003134898892045021, 'Test Accuracy': 85.33, 'Test Time': 3.4405887126922607}\n",
      "{'Epoch': 68, 'Train Loss': 0.00459788761138916, 'Train Accuracy': 78.36833333333334, 'Train Time': 59.886465549468994, 'Test Loss': 0.0027569884672760964, 'Test Accuracy': 87.26, 'Test Time': 3.4081037044525146}\n",
      "{'Epoch': 69, 'Train Loss': 0.004568945783376694, 'Train Accuracy': 78.38166666666666, 'Train Time': 59.68404674530029, 'Test Loss': 0.003191729983687401, 'Test Accuracy': 85.06, 'Test Time': 3.404583215713501}\n",
      "{'Epoch': 70, 'Train Loss': 0.004599236675103506, 'Train Accuracy': 78.265, 'Train Time': 59.71337962150574, 'Test Loss': 0.002763225793838501, 'Test Accuracy': 87.29, 'Test Time': 3.4450948238372803}\n",
      "{'Epoch': 71, 'Train Loss': 0.004579709703723589, 'Train Accuracy': 78.12666666666667, 'Train Time': 60.362964153289795, 'Test Loss': 0.0032285813689231875, 'Test Accuracy': 85.05, 'Test Time': 3.499621868133545}\n",
      "{'Epoch': 72, 'Train Loss': 0.0045664109239975615, 'Train Accuracy': 78.69, 'Train Time': 59.870161056518555, 'Test Loss': 0.0028414187893271445, 'Test Accuracy': 86.38, 'Test Time': 3.4589712619781494}\n",
      "{'Epoch': 73, 'Train Loss': 0.0045769485702117285, 'Train Accuracy': 78.42833333333333, 'Train Time': 60.40200972557068, 'Test Loss': 0.0027976968571543693, 'Test Accuracy': 86.61, 'Test Time': 3.4327781200408936}\n",
      "{'Epoch': 74, 'Train Loss': 0.0045539794837435085, 'Train Accuracy': 78.44666666666667, 'Train Time': 60.50149607658386, 'Test Loss': 0.002945332485437393, 'Test Accuracy': 86.0, 'Test Time': 3.41459584236145}\n",
      "{'Epoch': 75, 'Train Loss': 0.004578166195750236, 'Train Accuracy': 78.28333333333333, 'Train Time': 60.050124645233154, 'Test Loss': 0.002922324974834919, 'Test Accuracy': 86.13, 'Test Time': 3.387809991836548}\n",
      "{'Epoch': 76, 'Train Loss': 0.004550884534418583, 'Train Accuracy': 78.485, 'Train Time': 59.68852925300598, 'Test Loss': 0.0025102233558893204, 'Test Accuracy': 87.96, 'Test Time': 3.5552139282226562}\n",
      "{'Epoch': 77, 'Train Loss': 0.00457963024576505, 'Train Accuracy': 78.52833333333334, 'Train Time': 60.371543884277344, 'Test Loss': 0.0028198391139507293, 'Test Accuracy': 87.08, 'Test Time': 3.4545724391937256}\n",
      "{'Epoch': 78, 'Train Loss': 0.004551694037020207, 'Train Accuracy': 78.57333333333334, 'Train Time': 60.2852463722229, 'Test Loss': 0.0024890528082847597, 'Test Accuracy': 88.21, 'Test Time': 3.4182682037353516}\n",
      "{'Epoch': 79, 'Train Loss': 0.004496438802778721, 'Train Accuracy': 78.74666666666667, 'Train Time': 60.35742259025574, 'Test Loss': 0.0026440371289849283, 'Test Accuracy': 87.62, 'Test Time': 3.506993532180786}\n",
      "{'Epoch': 80, 'Train Loss': 0.004494449529051781, 'Train Accuracy': 78.86833333333334, 'Train Time': 59.597596883773804, 'Test Loss': 0.002613885597884655, 'Test Accuracy': 87.3, 'Test Time': 3.4897286891937256}\n",
      "{'Epoch': 81, 'Train Loss': 0.004540155432621638, 'Train Accuracy': 78.71666666666667, 'Train Time': 59.617451429367065, 'Test Loss': 0.0025987706050276758, 'Test Accuracy': 87.95, 'Test Time': 3.4609181880950928}\n",
      "{'Epoch': 82, 'Train Loss': 0.004528120631476244, 'Train Accuracy': 78.69833333333334, 'Train Time': 59.91899085044861, 'Test Loss': 0.0029083739399909975, 'Test Accuracy': 86.12, 'Test Time': 3.4386346340179443}\n",
      "{'Epoch': 83, 'Train Loss': 0.004467981128891309, 'Train Accuracy': 78.93666666666667, 'Train Time': 59.938729763031006, 'Test Loss': 0.0031694078236818315, 'Test Accuracy': 85.78, 'Test Time': 3.4988508224487305}\n",
      "{'Epoch': 84, 'Train Loss': 0.004476212731997172, 'Train Accuracy': 79.06333333333333, 'Train Time': 60.182652711868286, 'Test Loss': 0.0026340058699250222, 'Test Accuracy': 87.77, 'Test Time': 3.4092657566070557}\n",
      "{'Epoch': 85, 'Train Loss': 0.004487541896104813, 'Train Accuracy': 78.7, 'Train Time': 60.41614007949829, 'Test Loss': 0.0025347509399056434, 'Test Accuracy': 87.27, 'Test Time': 3.4309918880462646}\n",
      "{'Epoch': 86, 'Train Loss': 0.004481361827751001, 'Train Accuracy': 78.84833333333333, 'Train Time': 59.798354387283325, 'Test Loss': 0.0033324502810835837, 'Test Accuracy': 83.99, 'Test Time': 3.40562105178833}\n",
      "{'Epoch': 87, 'Train Loss': 0.004468456269303958, 'Train Accuracy': 78.95666666666666, 'Train Time': 59.697704792022705, 'Test Loss': 0.0025746084347367288, 'Test Accuracy': 87.81, 'Test Time': 3.4285154342651367}\n",
      "{'Epoch': 88, 'Train Loss': 0.004479839812715848, 'Train Accuracy': 78.91333333333333, 'Train Time': 60.051496505737305, 'Test Loss': 0.0026950371995568276, 'Test Accuracy': 87.5, 'Test Time': 3.4178850650787354}\n",
      "{'Epoch': 89, 'Train Loss': 0.004437077512343725, 'Train Accuracy': 79.12833333333333, 'Train Time': 59.935240030288696, 'Test Loss': 0.002726145949959755, 'Test Accuracy': 87.27, 'Test Time': 3.4405462741851807}\n",
      "{'Epoch': 90, 'Train Loss': 0.004466789497435093, 'Train Accuracy': 78.95333333333333, 'Train Time': 59.95814538002014, 'Test Loss': 0.0029243130043148996, 'Test Accuracy': 85.76, 'Test Time': 3.4859297275543213}\n",
      "{'Epoch': 91, 'Train Loss': 0.00446326471666495, 'Train Accuracy': 78.96333333333334, 'Train Time': 60.36009478569031, 'Test Loss': 0.0024389744594693185, 'Test Accuracy': 88.65, 'Test Time': 3.4560625553131104}\n",
      "{'Epoch': 92, 'Train Loss': 0.004411665101349354, 'Train Accuracy': 79.1, 'Train Time': 59.65316295623779, 'Test Loss': 0.0031992121621966362, 'Test Accuracy': 84.95, 'Test Time': 3.4229681491851807}\n",
      "{'Epoch': 93, 'Train Loss': 0.004421496371924877, 'Train Accuracy': 79.145, 'Train Time': 59.75110363960266, 'Test Loss': 0.0027913923650979998, 'Test Accuracy': 86.86, 'Test Time': 3.5855488777160645}\n",
      "{'Epoch': 94, 'Train Loss': 0.004457719110945861, 'Train Accuracy': 78.895, 'Train Time': 60.84969210624695, 'Test Loss': 0.002684728838503361, 'Test Accuracy': 87.53, 'Test Time': 3.4148874282836914}\n",
      "{'Epoch': 95, 'Train Loss': 0.004391411739091079, 'Train Accuracy': 79.34666666666666, 'Train Time': 59.87119650840759, 'Test Loss': 0.002780585515499115, 'Test Accuracy': 86.06, 'Test Time': 3.491581916809082}\n",
      "{'Epoch': 96, 'Train Loss': 0.004418749918043614, 'Train Accuracy': 79.21666666666667, 'Train Time': 60.14871859550476, 'Test Loss': 0.0025500859901309014, 'Test Accuracy': 87.68, 'Test Time': 3.4915153980255127}\n",
      "{'Epoch': 97, 'Train Loss': 0.00439396589299043, 'Train Accuracy': 79.215, 'Train Time': 60.105525970458984, 'Test Loss': 0.0025860825136303904, 'Test Accuracy': 87.48, 'Test Time': 3.4579830169677734}\n",
      "{'Epoch': 98, 'Train Loss': 0.004439389073848724, 'Train Accuracy': 79.05333333333333, 'Train Time': 59.63769054412842, 'Test Loss': 0.002897427360713482, 'Test Accuracy': 85.3, 'Test Time': 3.445037364959717}\n",
      "{'Epoch': 99, 'Train Loss': 0.004375768668949604, 'Train Accuracy': 79.37166666666667, 'Train Time': 60.30899906158447, 'Test Loss': 0.0024975437611341475, 'Test Accuracy': 88.27, 'Test Time': 3.483081579208374}\n",
      "{'Epoch': 100, 'Train Loss': 0.00435708306680123, 'Train Accuracy': 79.49333333333334, 'Train Time': 59.7328679561615, 'Test Loss': 0.002681829360127449, 'Test Accuracy': 87.0, 'Test Time': 3.481092929840088}\n"
     ]
    }
   ],
   "source": [
    "# Data_List = [\"CIFAR10\", \"CIFAR100\", \"IMAGENET\", \"MNIST\", \"FASION_MNIST\", \"PascalVOC\", \"Flowers102\"]\n",
    "Data_List = [\"FASION_MNIST\"]\n",
    "\n",
    "for DATA in Data_List:\n",
    "    trainloader, testloader, num_classes = LoadData(DATA, 128)\n",
    "\n",
    "    model = ResNet50(num_classes, 1).to(device)\n",
    "\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "\n",
    "    last_epoch = 0\n",
    "    num_epochs = 100\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(last_epoch,num_epochs):\n",
    "        t0 = time()\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loss, train_accuracy = train(model, trainloader, criterion, optimizer)\n",
    "        t1 = time()\n",
    "        test_loss, test_accuracy = test(model, testloader, criterion)\n",
    "        t2 = time()\n",
    "\n",
    "        data = {\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,\n",
    "            \"Train Time\": t1 - t0,\n",
    "            \"Test Loss\": test_loss,\n",
    "            \"Test Accuracy\": test_accuracy,\n",
    "            \"Test Time\": t2 - t1,\n",
    "        }\n",
    "        print(data)\n",
    "        history.append(data)\n",
    "\n",
    "    pd.DataFrame(history).to_json(f'./History/{DATA}-Neuron-new.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR10-ResNet50_85%.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
