{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPSy3VPHL5Uq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import deeplake\n",
    "from time import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V2SCe0hDNeaV",
    "outputId": "02ea31cc-a3e8-4b9e-da02-1f2821ca4e52"
   },
   "outputs": [],
   "source": [
    "def LoadData(DATA, batch_size):\n",
    "\n",
    "    if DATA == \"CIFAR10\":\n",
    "        root = '../Data/CIFAR10'\n",
    "        num_classes = 10\n",
    "\n",
    "        cifar10_train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        cifar10_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "        train = torchvision.datasets.CIFAR10(root=root, train=True, transform=cifar10_train_transform)\n",
    "        test = torchvision.datasets.CIFAR10(root=root, train=False, transform=cifar10_test_transform)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"CIFAR100\":\n",
    "        root = '../Data/CIFAR100'\n",
    "        num_classes = 100\n",
    "\n",
    "        cifar100_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(32, scale=(0.8, 1.2)), # Simulate scale variations\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=15), # Consider for object orientations\n",
    "            transforms.RandomGrayscale(p=0.2), # Optional for color augmentation\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Standard CIFAR-100 normalization\n",
    "        ])\n",
    "        cifar100_test_transform = transforms.Compose([\n",
    "            # transforms.Resize(32),\n",
    "            # transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.CIFAR100(root=root, train=True, transform=cifar100_train_transform)\n",
    "        test = torchvision.datasets.CIFAR100(root=root, train=False, transform=cifar100_test_transform)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"IMAGENET\":\n",
    "        root = '../Data/IMAGENET'\n",
    "        num_classes = 200\n",
    "\n",
    "        tiny_imagenet_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(64, scale=(0.8, 1.2), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        tiny_imagenet_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "\n",
    "        train = deeplake.load(\"hub://activeloop/tiny-imagenet-train\")\n",
    "        test = deeplake.load(\"hub://activeloop/tiny-imagenet-test\")\n",
    "\n",
    "        train.pytorch(transform = tiny_imagenet_train_transform, batch_size = batch_size, shuffle = True)\n",
    "        test.pytorch(transform = tiny_imagenet_test_transform, batch_size = batch_size, shuffle = False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"MNIST\":\n",
    "        root='../Data/MNIST'\n",
    "        num_classes = 10\n",
    "\n",
    "        mnist_train_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(10),  # Improve robustness\n",
    "            transforms.RandomHorizontalFlip(),  # Augment data\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "\n",
    "        mnist_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.MNIST(root=root, train=True, transform=mnist_train_transform, download=True)\n",
    "        test = torchvision.datasets.MNIST(root=root, train=False, transform=mnist_test_transform ,download=True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"FASION_MNIST\":\n",
    "        root='../Data/FASION_MNIST'\n",
    "        num_classes = 10\n",
    "\n",
    "        fashion_mnist_train_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(15),  # Improve robustness\n",
    "            transforms.RandomHorizontalFlip(),  # Augment data\n",
    "            transforms.RandomResizedCrop(28),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        fashion_mnist_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.FashionMNIST(root=root, train=True, transform=fashion_mnist_train_transform, download=True)\n",
    "        test = torchvision.datasets.FashionMNIST(root=root, train=False, transform=fashion_mnist_test_transform ,download=True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"PascalVOC\":\n",
    "        root = '../Data/PascalVOC'\n",
    "        num_classes = 20\n",
    "\n",
    "        voc_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
    "            transforms.RandomHorizontalFlip(),  # Randomly flip for horizontal invariance\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        voc_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.VOCDetection(root=root, year='2012', image_set='trainval', transform=voc_train_transform, download = True)\n",
    "        test = torchvision.datasets.VOCDetection(root=root, year='2012', image_set='trainval', transform=voc_test_transform, download = True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"Flowers102\":\n",
    "        root = '../Data/Flowers102'\n",
    "        num_classes = 102\n",
    "\n",
    "        oxford102_train_transform = transforms.Compose([\n",
    "            transforms.Resize(256),  # Adjust size based on your model\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),  # Simulate scale variations\n",
    "            transforms.RandomHorizontalFlip(),  # Increase data diversity\n",
    "            transforms.RandomRotation(15),  # Consider for specific flower orientations (optional)\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Introduce color variations\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  # ImageNet stats, adjust if needed\n",
    "        ])\n",
    "\n",
    "\n",
    "        oxford102_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "\n",
    "        train = torchvision.datasets.Flowers102(root=root, transform=oxford102_train_transform, download=True)\n",
    "        test = torchvision.datasets.Flowers102(root=root, transform=oxford102_test_transform, download = True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    return trainloader, testloader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVrCGU9jNkJb"
   },
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Ensemble(ResNet):\n",
    "    def __init__(self, modelA, modelB):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "\n",
    "    def forward(self, x,):\n",
    "\n",
    "        out1 = self.modelA.max_pool(self.modelA.relu(self.modelA.batch_norm1(self.modelA.conv1(x))))\n",
    "        out2 = self.modelB.max_pool(self.modelB.relu(self.modelB.batch_norm1(self.modelB.conv1(x))))\n",
    "\n",
    "        out1 = self.modelA.layer1(out1)\n",
    "        out2 = self.modelB.layer1(out2)\n",
    "        out = (out1+out2)/2\n",
    "        L = torch.mean(torch.pow((out1 - out) + (out2 - out), 2))\n",
    "\n",
    "        out1 = self.modelA.layer2(out)\n",
    "        out2 = self.modelB.layer2(out)\n",
    "        out = (out1+out2)/2\n",
    "        L += torch.mean(torch.pow((out1 - out) + (out2 - out), 2))\n",
    "\n",
    "        out1 = self.modelA.layer3(out)\n",
    "        out2 = self.modelB.layer3(out)\n",
    "        out = (out1+out2)/2\n",
    "        L += torch.mean(torch.pow((out1 - out) + (out2 - out), 2))\n",
    "\n",
    "        out1 = self.modelA.layer4(out)\n",
    "        out2 = self.modelB.layer4(out)\n",
    "        out = (out1+out2)/2\n",
    "        L += torch.mean(torch.pow((out1 - out) + (out2 - out), 2))\n",
    "\n",
    "        out1 = self.modelA.avgpool(out)\n",
    "        out2 = self.modelB.avgpool(out)\n",
    "        out = (out1+out2)/2\n",
    "\n",
    "        out = out.reshape(out.shape[0], -1)\n",
    "\n",
    "        out1 = self.modelA.fc(out)\n",
    "        out2 = self.modelB.fc(out)\n",
    "\n",
    "        # out = torch.max(out1, out2)\n",
    "        out = (out1+out2)/2\n",
    "        return out, L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, landaparam):\n",
    "    total = 0.\n",
    "    correct = 0.\n",
    "    running_loss = 0.\n",
    "\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, L = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        base_loss = criterion(outputs, labels)\n",
    "        loss = base_loss - (landaparam * L)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_loss = running_loss / total\n",
    "\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, criterion, landaparam):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs, L = model(inputs)\n",
    "            base_loss = criterion(outputs, labels)\n",
    "            loss = base_loss - (landaparam * L)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_loss = running_loss / total\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASION_MNIST successfully loaded.\n",
      "{'Epoch': 1, 'Train Loss': 0.024019487007459005, 'Train Accuracy': 36.31166666666667, 'Train Time': 79.90403318405151, 'Test Loss': 0.008841701555252076, 'Test Accuracy': 64.82, 'Test Time': 4.928772926330566}\n",
      "{'Epoch': 2, 'Train Loss': 0.016885210861762364, 'Train Accuracy': 43.665, 'Train Time': 87.56034922599792, 'Test Loss': 0.010162638628482818, 'Test Accuracy': 62.71, 'Test Time': 4.92589807510376}\n",
      "{'Epoch': 3, 'Train Loss': 0.01098663978477319, 'Train Accuracy': 53.70333333333333, 'Train Time': 87.29067730903625, 'Test Loss': 0.006978583085536957, 'Test Accuracy': 67.13, 'Test Time': 4.910336256027222}\n",
      "{'Epoch': 4, 'Train Loss': 0.009409222559134166, 'Train Accuracy': 57.568333333333335, 'Train Time': 87.74077320098877, 'Test Loss': 0.008303176307678222, 'Test Accuracy': 70.0, 'Test Time': 4.909787893295288}\n",
      "{'Epoch': 5, 'Train Loss': 0.00869082213540872, 'Train Accuracy': 59.79666666666667, 'Train Time': 87.48668456077576, 'Test Loss': 0.007670835012197495, 'Test Accuracy': 70.86, 'Test Time': 4.897704362869263}\n",
      "{'Epoch': 6, 'Train Loss': 0.008052816609541574, 'Train Accuracy': 61.736666666666665, 'Train Time': 87.36582803726196, 'Test Loss': 0.00854188688993454, 'Test Accuracy': 70.99, 'Test Time': 4.988279819488525}\n",
      "{'Epoch': 7, 'Train Loss': 0.007638948493202527, 'Train Accuracy': 63.788333333333334, 'Train Time': 87.90454578399658, 'Test Loss': 0.006132031881809235, 'Test Accuracy': 75.54, 'Test Time': 4.961703300476074}\n",
      "{'Epoch': 8, 'Train Loss': 0.0072900059709946315, 'Train Accuracy': 64.91166666666666, 'Train Time': 87.4038028717041, 'Test Loss': 0.005922679930925369, 'Test Accuracy': 75.82, 'Test Time': 4.975122690200806}\n",
      "{'Epoch': 9, 'Train Loss': 0.006916946473717689, 'Train Accuracy': 66.87, 'Train Time': 87.42873907089233, 'Test Loss': 0.004598653903603553, 'Test Accuracy': 78.36, 'Test Time': 5.001439571380615}\n",
      "{'Epoch': 10, 'Train Loss': 0.006764584502577782, 'Train Accuracy': 68.11833333333334, 'Train Time': 87.1348192691803, 'Test Loss': 0.0043909848272800445, 'Test Accuracy': 80.39, 'Test Time': 4.961552381515503}\n",
      "{'Epoch': 11, 'Train Loss': 0.007083533865213394, 'Train Accuracy': 66.13666666666667, 'Train Time': 86.91688370704651, 'Test Loss': 0.0042340339541435245, 'Test Accuracy': 79.79, 'Test Time': 4.857360124588013}\n",
      "{'Epoch': 12, 'Train Loss': 0.006604406480987867, 'Train Accuracy': 68.72333333333333, 'Train Time': 86.33919787406921, 'Test Loss': 0.004278901755809784, 'Test Accuracy': 79.98, 'Test Time': 4.857578754425049}\n",
      "{'Epoch': 13, 'Train Loss': 0.006353082363804182, 'Train Accuracy': 69.915, 'Train Time': 86.1827449798584, 'Test Loss': 0.004418286180496216, 'Test Accuracy': 79.44, 'Test Time': 4.967184543609619}\n",
      "{'Epoch': 14, 'Train Loss': 0.006180856629212698, 'Train Accuracy': 70.61, 'Train Time': 85.87404227256775, 'Test Loss': 0.004037571975588798, 'Test Accuracy': 81.28, 'Test Time': 4.8699305057525635}\n",
      "{'Epoch': 15, 'Train Loss': 0.006050439363718033, 'Train Accuracy': 71.41666666666667, 'Train Time': 85.91300535202026, 'Test Loss': 0.0036991244226694106, 'Test Accuracy': 82.66, 'Test Time': 4.907383441925049}\n",
      "{'Epoch': 16, 'Train Loss': 0.005899766940871874, 'Train Accuracy': 71.85333333333334, 'Train Time': 86.16891932487488, 'Test Loss': 0.0036458181262016298, 'Test Accuracy': 82.62, 'Test Time': 4.7754294872283936}\n",
      "{'Epoch': 17, 'Train Loss': 0.005825148184100787, 'Train Accuracy': 72.66666666666667, 'Train Time': 86.19449377059937, 'Test Loss': 0.0034182522147893904, 'Test Accuracy': 84.02, 'Test Time': 4.786924123764038}\n",
      "{'Epoch': 18, 'Train Loss': 0.005747276983658472, 'Train Accuracy': 72.95333333333333, 'Train Time': 86.49984192848206, 'Test Loss': 0.0033075357496738433, 'Test Accuracy': 84.41, 'Test Time': 4.867947816848755}\n",
      "{'Epoch': 19, 'Train Loss': 0.005623595183094343, 'Train Accuracy': 73.535, 'Train Time': 86.45946884155273, 'Test Loss': 0.0034075341790914537, 'Test Accuracy': 83.98, 'Test Time': 4.812131881713867}\n",
      "{'Epoch': 20, 'Train Loss': 0.0055845586881041525, 'Train Accuracy': 73.47833333333334, 'Train Time': 86.14162731170654, 'Test Loss': 0.0030028661236166953, 'Test Accuracy': 86.07, 'Test Time': 4.863630056381226}\n",
      "{'Epoch': 21, 'Train Loss': 0.005502503577868144, 'Train Accuracy': 73.96333333333334, 'Train Time': 86.75994157791138, 'Test Loss': 0.003913578709959984, 'Test Accuracy': 81.08, 'Test Time': 4.846422433853149}\n",
      "{'Epoch': 22, 'Train Loss': 0.005393740382790566, 'Train Accuracy': 74.58166666666666, 'Train Time': 86.20894861221313, 'Test Loss': 0.003242904990911484, 'Test Accuracy': 84.42, 'Test Time': 4.904225826263428}\n",
      "{'Epoch': 23, 'Train Loss': 0.005369401011864344, 'Train Accuracy': 74.83333333333333, 'Train Time': 77.10441851615906, 'Test Loss': 0.0033099528819322587, 'Test Accuracy': 85.02, 'Test Time': 3.6762843132019043}\n",
      "{'Epoch': 24, 'Train Loss': 0.005366482689976692, 'Train Accuracy': 74.64166666666667, 'Train Time': 64.10179471969604, 'Test Loss': 0.0035656043887138367, 'Test Accuracy': 82.84, 'Test Time': 3.638725996017456}\n",
      "{'Epoch': 25, 'Train Loss': 0.005268129027883212, 'Train Accuracy': 75.23, 'Train Time': 63.97195768356323, 'Test Loss': 0.003299313148856163, 'Test Accuracy': 84.48, 'Test Time': 3.6164612770080566}\n",
      "{'Epoch': 26, 'Train Loss': 0.005218781840304534, 'Train Accuracy': 75.28333333333333, 'Train Time': 63.62705397605896, 'Test Loss': 0.0034848314732313155, 'Test Accuracy': 82.91, 'Test Time': 3.7087252140045166}\n",
      "{'Epoch': 27, 'Train Loss': 0.0052010762547453245, 'Train Accuracy': 75.545, 'Train Time': 64.30381965637207, 'Test Loss': 0.004253502222895622, 'Test Accuracy': 81.62, 'Test Time': 3.6543750762939453}\n",
      "{'Epoch': 28, 'Train Loss': 0.0051416539192199705, 'Train Accuracy': 75.62666666666667, 'Train Time': 64.29885673522949, 'Test Loss': 0.0035057468563318255, 'Test Accuracy': 82.93, 'Test Time': 3.6998941898345947}\n",
      "{'Epoch': 29, 'Train Loss': 0.005170902166267236, 'Train Accuracy': 75.63, 'Train Time': 64.16488909721375, 'Test Loss': 0.002994331915676594, 'Test Accuracy': 85.52, 'Test Time': 3.7244603633880615}\n",
      "{'Epoch': 30, 'Train Loss': 0.005107894271612168, 'Train Accuracy': 75.83833333333334, 'Train Time': 63.54356002807617, 'Test Loss': 0.002975627675652504, 'Test Accuracy': 86.35, 'Test Time': 3.533081293106079}\n",
      "{'Epoch': 31, 'Train Loss': 0.005098484649757544, 'Train Accuracy': 75.98333333333333, 'Train Time': 63.92250967025757, 'Test Loss': 0.004180994147062302, 'Test Accuracy': 80.53, 'Test Time': 3.4699268341064453}\n",
      "{'Epoch': 32, 'Train Loss': 0.005054772966106733, 'Train Accuracy': 75.93333333333334, 'Train Time': 64.12496709823608, 'Test Loss': 0.0034423232764005662, 'Test Accuracy': 83.87, 'Test Time': 3.6125261783599854}\n",
      "{'Epoch': 33, 'Train Loss': 0.005011216146250566, 'Train Accuracy': 76.25333333333333, 'Train Time': 63.784416913986206, 'Test Loss': 0.003007347536087036, 'Test Accuracy': 86.11, 'Test Time': 3.7333760261535645}\n",
      "{'Epoch': 34, 'Train Loss': 0.004992137862741947, 'Train Accuracy': 76.34833333333333, 'Train Time': 64.41425728797913, 'Test Loss': 0.003409106433391571, 'Test Accuracy': 84.05, 'Test Time': 3.712569236755371}\n",
      "{'Epoch': 35, 'Train Loss': 0.004966844886044661, 'Train Accuracy': 76.55166666666666, 'Train Time': 64.05973482131958, 'Test Loss': 0.0032837862342596055, 'Test Accuracy': 84.8, 'Test Time': 3.568601608276367}\n",
      "{'Epoch': 36, 'Train Loss': 0.004992375771204631, 'Train Accuracy': 76.40833333333333, 'Train Time': 64.06468462944031, 'Test Loss': 0.0035813033670187, 'Test Accuracy': 84.53, 'Test Time': 3.696747064590454}\n",
      "{'Epoch': 37, 'Train Loss': 0.004936087262133757, 'Train Accuracy': 76.78666666666666, 'Train Time': 64.22671508789062, 'Test Loss': 0.003321291869878769, 'Test Accuracy': 84.11, 'Test Time': 3.6442604064941406}\n",
      "{'Epoch': 38, 'Train Loss': 0.004916925712426503, 'Train Accuracy': 76.69166666666666, 'Train Time': 64.10762453079224, 'Test Loss': 0.004019408342242241, 'Test Accuracy': 82.11, 'Test Time': 3.6371519565582275}\n",
      "{'Epoch': 39, 'Train Loss': 0.0049083510408798854, 'Train Accuracy': 76.89833333333333, 'Train Time': 63.86012816429138, 'Test Loss': 0.002714231823384762, 'Test Accuracy': 86.99, 'Test Time': 3.7086806297302246}\n",
      "{'Epoch': 40, 'Train Loss': 0.004846852879226208, 'Train Accuracy': 76.96, 'Train Time': 63.73573899269104, 'Test Loss': 0.00283608485609293, 'Test Accuracy': 86.6, 'Test Time': 3.644685745239258}\n",
      "{'Epoch': 41, 'Train Loss': 0.004876029205818971, 'Train Accuracy': 76.95666666666666, 'Train Time': 64.00489115715027, 'Test Loss': 0.0027576967999339104, 'Test Accuracy': 87.0, 'Test Time': 3.622154951095581}\n",
      "{'Epoch': 42, 'Train Loss': 0.0048137943238019945, 'Train Accuracy': 77.27333333333333, 'Train Time': 64.59303951263428, 'Test Loss': 0.004305361567437649, 'Test Accuracy': 82.39, 'Test Time': 3.7423791885375977}\n",
      "{'Epoch': 43, 'Train Loss': 0.004849682563046615, 'Train Accuracy': 77.28333333333333, 'Train Time': 64.20696926116943, 'Test Loss': 0.0027212947502732276, 'Test Accuracy': 86.98, 'Test Time': 3.6932590007781982}\n",
      "{'Epoch': 44, 'Train Loss': 0.004846731357276439, 'Train Accuracy': 77.085, 'Train Time': 64.35077905654907, 'Test Loss': 0.0028418269127607346, 'Test Accuracy': 86.86, 'Test Time': 3.6358892917633057}\n",
      "{'Epoch': 45, 'Train Loss': 0.004823449024061362, 'Train Accuracy': 77.27666666666667, 'Train Time': 64.22718405723572, 'Test Loss': 0.003123112019896507, 'Test Accuracy': 84.57, 'Test Time': 3.6621179580688477}\n",
      "{'Epoch': 46, 'Train Loss': 0.004765106548865636, 'Train Accuracy': 77.58333333333333, 'Train Time': 63.98757886886597, 'Test Loss': 0.0033574258476495745, 'Test Accuracy': 84.43, 'Test Time': 3.634931802749634}\n",
      "{'Epoch': 47, 'Train Loss': 0.004740804274380207, 'Train Accuracy': 77.43, 'Train Time': 63.77717566490173, 'Test Loss': 0.0029612489938735964, 'Test Accuracy': 86.33, 'Test Time': 3.6837430000305176}\n",
      "{'Epoch': 48, 'Train Loss': 0.004765519840518633, 'Train Accuracy': 77.675, 'Train Time': 64.65683197975159, 'Test Loss': 0.0027317521005868913, 'Test Accuracy': 87.04, 'Test Time': 3.6552553176879883}\n",
      "{'Epoch': 49, 'Train Loss': 0.004770273993909359, 'Train Accuracy': 77.47666666666667, 'Train Time': 64.08592391014099, 'Test Loss': 0.0029193501055240633, 'Test Accuracy': 86.12, 'Test Time': 3.6468310356140137}\n",
      "{'Epoch': 50, 'Train Loss': 0.004743214037517707, 'Train Accuracy': 77.44166666666666, 'Train Time': 64.45684504508972, 'Test Loss': 0.0026983522444963457, 'Test Accuracy': 87.44, 'Test Time': 3.6352646350860596}\n",
      "{'Epoch': 51, 'Train Loss': 0.004715272343655427, 'Train Accuracy': 77.88, 'Train Time': 64.1185564994812, 'Test Loss': 0.003136874374747276, 'Test Accuracy': 84.09, 'Test Time': 3.608508586883545}\n",
      "{'Epoch': 52, 'Train Loss': 0.004702324532965819, 'Train Accuracy': 77.70666666666666, 'Train Time': 64.00131940841675, 'Test Loss': 0.0025394859328866006, 'Test Accuracy': 88.16, 'Test Time': 3.612455368041992}\n",
      "{'Epoch': 53, 'Train Loss': 0.004705916156371434, 'Train Accuracy': 77.89333333333333, 'Train Time': 64.27634358406067, 'Test Loss': 0.0033944563210010527, 'Test Accuracy': 84.77, 'Test Time': 3.6276023387908936}\n",
      "{'Epoch': 54, 'Train Loss': 0.004694687747458617, 'Train Accuracy': 77.76666666666667, 'Train Time': 63.99506640434265, 'Test Loss': 0.002788220809400082, 'Test Accuracy': 86.8, 'Test Time': 3.61413836479187}\n",
      "{'Epoch': 55, 'Train Loss': 0.004678655868271987, 'Train Accuracy': 77.97166666666666, 'Train Time': 64.36378121376038, 'Test Loss': 0.0030351661756634713, 'Test Accuracy': 85.58, 'Test Time': 3.6441762447357178}\n",
      "{'Epoch': 56, 'Train Loss': 0.004700776051481565, 'Train Accuracy': 77.95166666666667, 'Train Time': 64.13622975349426, 'Test Loss': 0.0027218483582139015, 'Test Accuracy': 86.7, 'Test Time': 3.618065118789673}\n",
      "{'Epoch': 57, 'Train Loss': 0.004649224211275577, 'Train Accuracy': 78.10666666666667, 'Train Time': 63.783488035202026, 'Test Loss': 0.0027485832884907723, 'Test Accuracy': 86.92, 'Test Time': 3.5937955379486084}\n",
      "{'Epoch': 58, 'Train Loss': 0.004643212114274502, 'Train Accuracy': 78.13833333333334, 'Train Time': 64.05164003372192, 'Test Loss': 0.0023696421891450884, 'Test Accuracy': 88.97, 'Test Time': 3.5371804237365723}\n",
      "{'Epoch': 59, 'Train Loss': 0.004634251375496387, 'Train Accuracy': 78.125, 'Train Time': 63.99695348739624, 'Test Loss': 0.0031724436670541763, 'Test Accuracy': 84.59, 'Test Time': 3.6474907398223877}\n",
      "{'Epoch': 60, 'Train Loss': 0.004620265772442023, 'Train Accuracy': 78.12166666666667, 'Train Time': 63.957438468933105, 'Test Loss': 0.003090313844382763, 'Test Accuracy': 84.48, 'Test Time': 3.6975040435791016}\n",
      "{'Epoch': 61, 'Train Loss': 0.004615182804564635, 'Train Accuracy': 78.18333333333334, 'Train Time': 63.976348638534546, 'Test Loss': 0.0026978189036250115, 'Test Accuracy': 87.34, 'Test Time': 3.744570732116699}\n",
      "{'Epoch': 62, 'Train Loss': 0.004587089906632901, 'Train Accuracy': 78.40333333333334, 'Train Time': 63.50563430786133, 'Test Loss': 0.002552011241018772, 'Test Accuracy': 87.81, 'Test Time': 3.6490561962127686}\n",
      "{'Epoch': 63, 'Train Loss': 0.004533183420201143, 'Train Accuracy': 78.585, 'Train Time': 63.941481828689575, 'Test Loss': 0.0027078823894262313, 'Test Accuracy': 86.89, 'Test Time': 3.6875014305114746}\n",
      "{'Epoch': 64, 'Train Loss': 0.004562629099190235, 'Train Accuracy': 78.52, 'Train Time': 64.07521104812622, 'Test Loss': 0.0026662923246622084, 'Test Accuracy': 87.42, 'Test Time': 3.6137595176696777}\n",
      "{'Epoch': 65, 'Train Loss': 0.004553021871546904, 'Train Accuracy': 78.37166666666667, 'Train Time': 64.41809129714966, 'Test Loss': 0.0026908929392695426, 'Test Accuracy': 86.83, 'Test Time': 3.6658341884613037}\n",
      "{'Epoch': 66, 'Train Loss': 0.004617724967499574, 'Train Accuracy': 78.28, 'Train Time': 64.12858724594116, 'Test Loss': 0.0027563736379146576, 'Test Accuracy': 86.79, 'Test Time': 3.6185431480407715}\n",
      "{'Epoch': 67, 'Train Loss': 0.004581816409528256, 'Train Accuracy': 78.41333333333333, 'Train Time': 64.12812852859497, 'Test Loss': 0.0025591145783662797, 'Test Accuracy': 87.8, 'Test Time': 3.6558706760406494}\n",
      "{'Epoch': 68, 'Train Loss': 0.004562240851918856, 'Train Accuracy': 78.535, 'Train Time': 63.75349712371826, 'Test Loss': 0.00263751852363348, 'Test Accuracy': 87.43, 'Test Time': 3.728400468826294}\n",
      "{'Epoch': 69, 'Train Loss': 0.004509654813011487, 'Train Accuracy': 78.77333333333333, 'Train Time': 64.08523035049438, 'Test Loss': 0.0025109391540288927, 'Test Accuracy': 88.02, 'Test Time': 3.6527326107025146}\n",
      "{'Epoch': 70, 'Train Loss': 0.004555772119760514, 'Train Accuracy': 78.51166666666667, 'Train Time': 52.8260498046875, 'Test Loss': 0.002865935477614403, 'Test Accuracy': 86.72, 'Test Time': 2.5444283485412598}\n",
      "{'Epoch': 71, 'Train Loss': 0.004537142360210419, 'Train Accuracy': 78.39166666666667, 'Train Time': 46.164225578308105, 'Test Loss': 0.0025301238849759103, 'Test Accuracy': 88.54, 'Test Time': 2.6773571968078613}\n",
      "{'Epoch': 72, 'Train Loss': 0.004480018338064353, 'Train Accuracy': 78.85666666666667, 'Train Time': 46.96213722229004, 'Test Loss': 0.0026522857189178466, 'Test Accuracy': 87.63, 'Test Time': 2.7087643146514893}\n",
      "{'Epoch': 73, 'Train Loss': 0.004491248808801174, 'Train Accuracy': 78.775, 'Train Time': 47.05557894706726, 'Test Loss': 0.002451640699803829, 'Test Accuracy': 88.63, 'Test Time': 2.4520654678344727}\n",
      "{'Epoch': 74, 'Train Loss': 0.004471726032098135, 'Train Accuracy': 78.80333333333333, 'Train Time': 45.304067850112915, 'Test Loss': 0.0027708465948700907, 'Test Accuracy': 86.46, 'Test Time': 2.548459768295288}\n",
      "{'Epoch': 75, 'Train Loss': 0.004512488172451655, 'Train Accuracy': 78.69333333333333, 'Train Time': 45.237338066101074, 'Test Loss': 0.002618238592147827, 'Test Accuracy': 87.3, 'Test Time': 2.5939712524414062}\n",
      "{'Epoch': 76, 'Train Loss': 0.004460237276057402, 'Train Accuracy': 78.935, 'Train Time': 46.54321336746216, 'Test Loss': 0.0025843401595950126, 'Test Accuracy': 88.08, 'Test Time': 2.663531541824341}\n",
      "{'Epoch': 77, 'Train Loss': 0.004509164103865623, 'Train Accuracy': 78.735, 'Train Time': 45.894031047821045, 'Test Loss': 0.0026262936234474183, 'Test Accuracy': 87.39, 'Test Time': 2.567354202270508}\n",
      "{'Epoch': 78, 'Train Loss': 0.004484876416126887, 'Train Accuracy': 78.78166666666667, 'Train Time': 45.36768102645874, 'Test Loss': 0.002801125572621822, 'Test Accuracy': 86.78, 'Test Time': 2.634397268295288}\n",
      "{'Epoch': 79, 'Train Loss': 0.004444615288078785, 'Train Accuracy': 79.075, 'Train Time': 46.504446268081665, 'Test Loss': 0.002517379629611969, 'Test Accuracy': 87.84, 'Test Time': 2.565416097640991}\n",
      "{'Epoch': 80, 'Train Loss': 0.00444020041624705, 'Train Accuracy': 78.84833333333333, 'Train Time': 46.7084002494812, 'Test Loss': 0.0028541439086198807, 'Test Accuracy': 86.66, 'Test Time': 2.645256519317627}\n",
      "{'Epoch': 81, 'Train Loss': 0.004401120751599471, 'Train Accuracy': 79.23833333333333, 'Train Time': 46.26037526130676, 'Test Loss': 0.0022758727252483366, 'Test Accuracy': 89.21, 'Test Time': 2.542233943939209}\n",
      "{'Epoch': 82, 'Train Loss': 0.004446958307425181, 'Train Accuracy': 78.91333333333333, 'Train Time': 45.08534526824951, 'Test Loss': 0.0025704490423202513, 'Test Accuracy': 88.07, 'Test Time': 2.557864189147949}\n",
      "{'Epoch': 83, 'Train Loss': 0.004424374593794346, 'Train Accuracy': 79.02333333333333, 'Train Time': 45.72074007987976, 'Test Loss': 0.0028894386366009714, 'Test Accuracy': 87.18, 'Test Time': 2.600375175476074}\n",
      "{'Epoch': 84, 'Train Loss': 0.004442252675692241, 'Train Accuracy': 79.155, 'Train Time': 45.852943420410156, 'Test Loss': 0.0026898761451244354, 'Test Accuracy': 87.85, 'Test Time': 2.4703028202056885}\n",
      "{'Epoch': 85, 'Train Loss': 0.004382913738489151, 'Train Accuracy': 79.21166666666667, 'Train Time': 45.68125247955322, 'Test Loss': 0.002652254121005535, 'Test Accuracy': 87.55, 'Test Time': 2.633171319961548}\n",
      "{'Epoch': 86, 'Train Loss': 0.004405171379446984, 'Train Accuracy': 79.18, 'Train Time': 46.03870606422424, 'Test Loss': 0.0030525255501270294, 'Test Accuracy': 85.46, 'Test Time': 2.638711929321289}\n",
      "{'Epoch': 87, 'Train Loss': 0.004386771338184675, 'Train Accuracy': 79.08333333333333, 'Train Time': 46.396358251571655, 'Test Loss': 0.00291675546169281, 'Test Accuracy': 86.1, 'Test Time': 2.634880781173706}\n",
      "{'Epoch': 88, 'Train Loss': 0.004382393830021223, 'Train Accuracy': 79.37666666666667, 'Train Time': 46.64012145996094, 'Test Loss': 0.0024861916542053223, 'Test Accuracy': 88.36, 'Test Time': 2.5706846714019775}\n",
      "{'Epoch': 89, 'Train Loss': 0.004377673742175102, 'Train Accuracy': 79.27666666666667, 'Train Time': 45.089083194732666, 'Test Loss': 0.0025419935315847395, 'Test Accuracy': 88.14, 'Test Time': 2.5925047397613525}\n",
      "{'Epoch': 90, 'Train Loss': 0.004398583410680294, 'Train Accuracy': 79.14166666666667, 'Train Time': 45.440526723861694, 'Test Loss': 0.0024823464468121527, 'Test Accuracy': 88.25, 'Test Time': 2.6377575397491455}\n",
      "{'Epoch': 91, 'Train Loss': 0.004359264999628067, 'Train Accuracy': 79.52333333333333, 'Train Time': 46.115856409072876, 'Test Loss': 0.002408324374258518, 'Test Accuracy': 88.39, 'Test Time': 2.5764565467834473}\n",
      "{'Epoch': 92, 'Train Loss': 0.004338075324892997, 'Train Accuracy': 79.41666666666667, 'Train Time': 45.45787811279297, 'Test Loss': 0.002666014860570431, 'Test Accuracy': 87.3, 'Test Time': 2.5798206329345703}\n",
      "{'Epoch': 93, 'Train Loss': 0.004303791411717732, 'Train Accuracy': 79.87166666666667, 'Train Time': 45.68382143974304, 'Test Loss': 0.002563163974881172, 'Test Accuracy': 87.93, 'Test Time': 2.602311134338379}\n",
      "{'Epoch': 94, 'Train Loss': 0.004382499995827675, 'Train Accuracy': 79.415, 'Train Time': 45.74842810630798, 'Test Loss': 0.0024521334409713744, 'Test Accuracy': 88.36, 'Test Time': 2.5678913593292236}\n",
      "{'Epoch': 95, 'Train Loss': 0.004308395298818747, 'Train Accuracy': 79.685, 'Train Time': 45.79676270484924, 'Test Loss': 0.0032948350638151167, 'Test Accuracy': 86.35, 'Test Time': 2.540860176086426}\n",
      "{'Epoch': 96, 'Train Loss': 0.004334603936473528, 'Train Accuracy': 79.36333333333333, 'Train Time': 45.61329460144043, 'Test Loss': 0.0026482881024479867, 'Test Accuracy': 87.71, 'Test Time': 2.516914129257202}\n",
      "{'Epoch': 97, 'Train Loss': 0.004308193710446358, 'Train Accuracy': 79.65833333333333, 'Train Time': 44.725937843322754, 'Test Loss': 0.002457150137424469, 'Test Accuracy': 88.28, 'Test Time': 2.5243732929229736}\n",
      "{'Epoch': 98, 'Train Loss': 0.004303506169716517, 'Train Accuracy': 79.67, 'Train Time': 45.38103127479553, 'Test Loss': 0.0024112950190901756, 'Test Accuracy': 88.76, 'Test Time': 2.6263933181762695}\n",
      "{'Epoch': 99, 'Train Loss': 0.004348878599206607, 'Train Accuracy': 79.575, 'Train Time': 45.54522490501404, 'Test Loss': 0.002450770388543606, 'Test Accuracy': 88.39, 'Test Time': 2.535414695739746}\n",
      "{'Epoch': 100, 'Train Loss': 0.004288888027767341, 'Train Accuracy': 79.74333333333334, 'Train Time': 45.79786205291748, 'Test Loss': 0.0023635799661278723, 'Test Accuracy': 89.01, 'Test Time': 2.6220619678497314}\n"
     ]
    }
   ],
   "source": [
    "# Data_List = [\"CIFAR10\", \"CIFAR100\", \"IMAGENET\", \"MNIST\", \"FASION_MNIST\", \"PascalVOC\", \"Flowers102\"]\n",
    "Data_List = [\"FASION_MNIST\"]\n",
    "\n",
    "for DATA in Data_List:\n",
    "    trainloader, testloader, num_classes = LoadData(DATA, 128)\n",
    "\n",
    "    first_model = ResNet50(num_classes, 1).to(device)\n",
    "    second_model = ResNet50(num_classes, 1).to(device)\n",
    "\n",
    "    model = Layer_Ensemble(first_model, second_model)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "    landaparam = 1e-3\n",
    "\n",
    "    last_epoch = 0\n",
    "    num_epochs = 100\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(last_epoch,num_epochs):\n",
    "        t0 = time()\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loss, train_accuracy = train(model, trainloader, criterion, optimizer, landaparam)\n",
    "        t1 = time()\n",
    "        test_loss, test_accuracy = test(model, testloader, criterion,landaparam)\n",
    "        t2 = time()\n",
    "\n",
    "        data = {\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,\n",
    "            \"Train Time\": t1 - t0,\n",
    "            \"Test Loss\": test_loss,\n",
    "            \"Test Accuracy\": test_accuracy,\n",
    "            \"Test Time\": t2 - t1,\n",
    "        }\n",
    "        print(data)\n",
    "        history.append(data)\n",
    "\n",
    "    pd.DataFrame(history).to_json(f'./History/{DATA}-Layer-Loss-new.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR10-ResNet50_85%.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
