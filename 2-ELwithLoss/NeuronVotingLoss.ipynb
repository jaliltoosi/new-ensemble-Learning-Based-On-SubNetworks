{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPSy3VPHL5Uq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import deeplake\n",
    "from time import time\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V2SCe0hDNeaV",
    "outputId": "02ea31cc-a3e8-4b9e-da02-1f2821ca4e52"
   },
   "outputs": [],
   "source": [
    "def LoadData(DATA, batch_size):\n",
    "\n",
    "    if DATA == \"CIFAR10\":\n",
    "        root = '../Data/CIFAR10'\n",
    "        num_classes = 10\n",
    "\n",
    "        cifar10_train_transform = transforms.Compose([\n",
    "            transforms.RandomCrop(32),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        cifar10_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "        train = torchvision.datasets.CIFAR10(root=root, train=True, transform=cifar10_train_transform)\n",
    "        test = torchvision.datasets.CIFAR10(root=root, train=False, transform=cifar10_test_transform)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"CIFAR100\":\n",
    "        root = '../Data/CIFAR100'\n",
    "        num_classes = 100\n",
    "\n",
    "        cifar100_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(32, scale=(0.8, 1.2)), # Simulate scale variations\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomRotation(degrees=15), # Consider for object orientations\n",
    "            transforms.RandomGrayscale(p=0.2), # Optional for color augmentation\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # Standard CIFAR-100 normalization\n",
    "        ])\n",
    "        cifar100_test_transform = transforms.Compose([\n",
    "            # transforms.Resize(32),\n",
    "            # transforms.CenterCrop(32),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.CIFAR100(root=root, train=True, transform=cifar100_train_transform)\n",
    "        test = torchvision.datasets.CIFAR100(root=root, train=False, transform=cifar100_test_transform)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size,shuffle=False, num_workers=2)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"IMAGENET\":\n",
    "        root = '../Data/IMAGENET'\n",
    "        num_classes = 200\n",
    "\n",
    "        tiny_imagenet_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(64, scale=(0.8, 1.2), interpolation=transforms.InterpolationMode.BILINEAR),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "        tiny_imagenet_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "            ])\n",
    "\n",
    "        train = deeplake.load(\"hub://activeloop/tiny-imagenet-train\")\n",
    "        test = deeplake.load(\"hub://activeloop/tiny-imagenet-test\")\n",
    "\n",
    "        train.pytorch(transform = tiny_imagenet_train_transform, batch_size = batch_size, shuffle = True)\n",
    "        test.pytorch(transform = tiny_imagenet_test_transform, batch_size = batch_size, shuffle = False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"MNIST\":\n",
    "        root='../Data/MNIST'\n",
    "        num_classes = 10\n",
    "\n",
    "        mnist_train_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(10),  # Improve robustness\n",
    "            transforms.RandomHorizontalFlip(),  # Augment data\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "\n",
    "        mnist_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.MNIST(root=root, train=True, transform=mnist_train_transform, download=True)\n",
    "        test = torchvision.datasets.MNIST(root=root, train=False, transform=mnist_test_transform ,download=True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"FASION_MNIST\":\n",
    "        root='../Data/FASION_MNIST'\n",
    "        num_classes = 10\n",
    "\n",
    "        fashion_mnist_train_transform = transforms.Compose([\n",
    "            transforms.RandomRotation(15),  # Improve robustness\n",
    "            transforms.RandomHorizontalFlip(),  # Augment data\n",
    "            transforms.RandomResizedCrop(28),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "        fashion_mnist_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5,), (0.5,))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.FashionMNIST(root=root, train=True, transform=fashion_mnist_train_transform, download=True)\n",
    "        test = torchvision.datasets.FashionMNIST(root=root, train=False, transform=fashion_mnist_test_transform ,download=True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"PascalVOC\":\n",
    "        root = '../Data/PascalVOC'\n",
    "        num_classes = 20\n",
    "\n",
    "        voc_train_transform = transforms.Compose([\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),\n",
    "            transforms.RandomHorizontalFlip(),  # Randomly flip for horizontal invariance\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        voc_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "        train = torchvision.datasets.VOCDetection(root=root, year='2012', image_set='trainval', transform=voc_train_transform, download = True)\n",
    "        test = torchvision.datasets.VOCDetection(root=root, year='2012', image_set='trainval', transform=voc_test_transform, download = True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    elif DATA == \"Flowers102\":\n",
    "        root = '../Data/Flowers102'\n",
    "        num_classes = 102\n",
    "\n",
    "        oxford102_train_transform = transforms.Compose([\n",
    "            transforms.Resize(256),  # Adjust size based on your model\n",
    "            transforms.RandomResizedCrop(224, scale=(0.8, 1.2)),  # Simulate scale variations\n",
    "            transforms.RandomHorizontalFlip(),  # Increase data diversity\n",
    "            transforms.RandomRotation(15),  # Consider for specific flower orientations (optional)\n",
    "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2),  # Introduce color variations\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))  # ImageNet stats, adjust if needed\n",
    "        ])\n",
    "\n",
    "\n",
    "        oxford102_test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "\n",
    "\n",
    "        train = torchvision.datasets.Flowers102(root=root, transform=oxford102_train_transform, download=True)\n",
    "        test = torchvision.datasets.Flowers102(root=root, transform=oxford102_test_transform, download = True)\n",
    "\n",
    "        trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "        testloader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "        print(DATA + \" successfully loaded.\")\n",
    "\n",
    "    return trainloader, testloader, num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVrCGU9jNkJb"
   },
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1a = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1a = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2a = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2a = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3a = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3a = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "        self.conv1b = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1b = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv2b = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2b = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.conv3b = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3b = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "\n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        global L\n",
    "\n",
    "        identity = x.clone()\n",
    "        xa = self.relu(self.batch_norm1a(self.conv1a(x)))\n",
    "        xb = self.relu(self.batch_norm1b(self.conv1b(x)))\n",
    "        x = (xa + xb)/2\n",
    "        L += torch.mean(torch.pow((xa - x) + (xb - x), 2))\n",
    "\n",
    "        xa = self.relu(self.batch_norm2a(self.conv2a(x)))\n",
    "        xb = self.relu(self.batch_norm2b(self.conv2b(x)))\n",
    "        x = (xa + xb)/2\n",
    "        L += torch.mean(torch.pow((xa - x) + (xb - x), 2))\n",
    "\n",
    "        xa = self.batch_norm3a(self.conv3a(x))\n",
    "        xb = self.batch_norm3b(self.conv3b(x))\n",
    "        x = (xa + xb)/2\n",
    "        L += torch.mean(torch.pow((xa - x) + (xb - x), 2))\n",
    "\n",
    "\n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*ResBlock.expansion, num_classes)\n",
    "\n",
    "        global L\n",
    "        L = 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        global L\n",
    "\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        l1 = L\n",
    "        L = 0\n",
    "        x = self.layer2(x)\n",
    "        l2 = L\n",
    "        L = 0\n",
    "        x = self.layer3(x)\n",
    "        l3 = L\n",
    "        L = 0\n",
    "        x = self.layer4(x)\n",
    "        l4 = L\n",
    "        L = 0\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        LL = (l1 + l2 + l3 + l4)/4\n",
    "\n",
    "        return x, LL\n",
    "\n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "\n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "\n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, criterion, optimizer, landaparam):\n",
    "    total = 0.\n",
    "    correct = 0.\n",
    "    running_loss = 0.\n",
    "    for inputs, labels in dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs, LL = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        base_loss = criterion(outputs, labels)\n",
    "        loss = base_loss - (landaparam * LL)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    train_accuracy = 100 * correct / total\n",
    "    train_loss = running_loss / total\n",
    "    return train_loss, train_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataloader, criterion, landaparam):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs, LL = model(inputs)\n",
    "\n",
    "            base_loss = criterion(outputs, labels)\n",
    "            loss = base_loss - (landaparam * LL)\n",
    "            total += labels.size(0)\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            running_loss += loss.item()\n",
    "    test_accuracy = 100 * correct / total\n",
    "    test_loss = running_loss / total\n",
    "\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASION_MNIST successfully loaded.\n",
      "{'Epoch': 1, 'Train Loss': 0.015421168571710586, 'Train Accuracy': 38.57833333333333, 'Train Time': 108.79418873786926, 'Test Loss': 0.009520590329170226, 'Test Accuracy': 64.4, 'Test Time': 6.596938848495483}\n",
      "{'Epoch': 2, 'Train Loss': 0.009716101876894633, 'Train Accuracy': 56.28, 'Train Time': 108.50012755393982, 'Test Loss': 0.00647969885468483, 'Test Accuracy': 71.96, 'Test Time': 6.620638370513916}\n",
      "{'Epoch': 3, 'Train Loss': 0.00844414428671201, 'Train Accuracy': 60.943333333333335, 'Train Time': 107.45290350914001, 'Test Loss': 0.006145624095201492, 'Test Accuracy': 71.03, 'Test Time': 6.612884759902954}\n",
      "{'Epoch': 4, 'Train Loss': 0.008482145037253698, 'Train Accuracy': 61.718333333333334, 'Train Time': 108.96431946754456, 'Test Loss': 0.00516291557252407, 'Test Accuracy': 75.29, 'Test Time': 6.445012092590332}\n",
      "{'Epoch': 5, 'Train Loss': 0.007747160944342613, 'Train Accuracy': 64.11333333333333, 'Train Time': 109.06385827064514, 'Test Loss': 0.005123968514800072, 'Test Accuracy': 76.74, 'Test Time': 6.361603021621704}\n",
      "{'Epoch': 6, 'Train Loss': 0.007125241533915202, 'Train Accuracy': 66.395, 'Train Time': 107.50911736488342, 'Test Loss': 0.004266289407014847, 'Test Accuracy': 80.13, 'Test Time': 6.455602407455444}\n",
      "{'Epoch': 7, 'Train Loss': 0.00680546059012413, 'Train Accuracy': 67.89, 'Train Time': 109.35780000686646, 'Test Loss': 0.004036219096183777, 'Test Accuracy': 81.28, 'Test Time': 6.636924505233765}\n",
      "{'Epoch': 8, 'Train Loss': 0.006596591858069102, 'Train Accuracy': 69.11833333333334, 'Train Time': 108.10447120666504, 'Test Loss': 0.004197110220789909, 'Test Accuracy': 80.56, 'Test Time': 6.598529815673828}\n",
      "{'Epoch': 9, 'Train Loss': 0.006403212161858876, 'Train Accuracy': 69.91, 'Train Time': 106.49038100242615, 'Test Loss': 0.0037040344536304476, 'Test Accuracy': 83.27, 'Test Time': 6.392535924911499}\n",
      "{'Epoch': 10, 'Train Loss': 0.006332975417375565, 'Train Accuracy': 70.285, 'Train Time': 107.24747800827026, 'Test Loss': 0.0036061633437871935, 'Test Accuracy': 83.22, 'Test Time': 6.191920280456543}\n",
      "{'Epoch': 11, 'Train Loss': 0.006091184615095457, 'Train Accuracy': 71.355, 'Train Time': 106.49424886703491, 'Test Loss': 0.0034407215029001238, 'Test Accuracy': 83.69, 'Test Time': 6.256251573562622}\n",
      "{'Epoch': 12, 'Train Loss': 0.005983514311909676, 'Train Accuracy': 71.81, 'Train Time': 106.71538138389587, 'Test Loss': 0.0034312884628772736, 'Test Accuracy': 83.68, 'Test Time': 6.417239189147949}\n",
      "{'Epoch': 13, 'Train Loss': 0.005909514478345712, 'Train Accuracy': 72.31166666666667, 'Train Time': 107.1610758304596, 'Test Loss': 0.003620817339420319, 'Test Accuracy': 83.16, 'Test Time': 6.406468391418457}\n",
      "{'Epoch': 14, 'Train Loss': 0.005833467815319697, 'Train Accuracy': 72.57833333333333, 'Train Time': 105.44517540931702, 'Test Loss': 0.00341244438290596, 'Test Accuracy': 83.88, 'Test Time': 6.390927791595459}\n",
      "{'Epoch': 15, 'Train Loss': 0.005779830354948838, 'Train Accuracy': 73.00833333333334, 'Train Time': 105.63474774360657, 'Test Loss': 0.003592347192764282, 'Test Accuracy': 83.06, 'Test Time': 6.359440565109253}\n",
      "{'Epoch': 16, 'Train Loss': 0.005779606121778488, 'Train Accuracy': 72.85666666666667, 'Train Time': 107.13648700714111, 'Test Loss': 0.003326435959339142, 'Test Accuracy': 84.05, 'Test Time': 6.434012413024902}\n",
      "{'Epoch': 17, 'Train Loss': 0.008935897673169772, 'Train Accuracy': 62.04666666666667, 'Train Time': 105.46247839927673, 'Test Loss': 0.006295900470018387, 'Test Accuracy': 69.88, 'Test Time': 6.535565376281738}\n",
      "{'Epoch': 18, 'Train Loss': 0.008351237393418948, 'Train Accuracy': 60.65833333333333, 'Train Time': 101.73842215538025, 'Test Loss': 0.006508331364393234, 'Test Accuracy': 68.68, 'Test Time': 4.500710725784302}\n",
      "{'Epoch': 19, 'Train Loss': 0.007323489199082056, 'Train Accuracy': 65.04666666666667, 'Train Time': 75.18518233299255, 'Test Loss': 0.00486255147755146, 'Test Accuracy': 76.7, 'Test Time': 4.565908432006836}\n",
      "{'Epoch': 20, 'Train Loss': 0.00694610429306825, 'Train Accuracy': 66.805, 'Train Time': 75.2386827468872, 'Test Loss': 0.004164787030220032, 'Test Accuracy': 80.16, 'Test Time': 4.569708347320557}\n",
      "{'Epoch': 21, 'Train Loss': 0.0066145296335220335, 'Train Accuracy': 68.39, 'Train Time': 75.99906730651855, 'Test Loss': 0.004332973599433899, 'Test Accuracy': 80.04, 'Test Time': 4.537679433822632}\n",
      "{'Epoch': 22, 'Train Loss': 0.006457291163007419, 'Train Accuracy': 69.09666666666666, 'Train Time': 75.66470527648926, 'Test Loss': 0.003888506591320038, 'Test Accuracy': 82.24, 'Test Time': 4.60357928276062}\n",
      "{'Epoch': 23, 'Train Loss': 0.006302021585901579, 'Train Accuracy': 70.01333333333334, 'Train Time': 74.76465225219727, 'Test Loss': 0.0044527501732110975, 'Test Accuracy': 78.16, 'Test Time': 4.628213882446289}\n",
      "{'Epoch': 24, 'Train Loss': 0.006156692571441333, 'Train Accuracy': 70.81333333333333, 'Train Time': 75.00695180892944, 'Test Loss': 0.004446457523107529, 'Test Accuracy': 78.56, 'Test Time': 4.638154745101929}\n",
      "{'Epoch': 25, 'Train Loss': 0.006138072923819224, 'Train Accuracy': 70.755, 'Train Time': 75.48733592033386, 'Test Loss': 0.003649147808551788, 'Test Accuracy': 82.33, 'Test Time': 4.430824041366577}\n",
      "{'Epoch': 26, 'Train Loss': 0.0060253273655970895, 'Train Accuracy': 71.545, 'Train Time': 74.40931844711304, 'Test Loss': 0.003554649558663368, 'Test Accuracy': 82.82, 'Test Time': 4.597956657409668}\n",
      "{'Epoch': 27, 'Train Loss': 0.005908776020010312, 'Train Accuracy': 71.99166666666666, 'Train Time': 75.08206176757812, 'Test Loss': 0.003521137011051178, 'Test Accuracy': 82.88, 'Test Time': 4.541264057159424}\n",
      "{'Epoch': 28, 'Train Loss': 0.0058075988034407295, 'Train Accuracy': 72.5, 'Train Time': 74.79251527786255, 'Test Loss': 0.003331893849372864, 'Test Accuracy': 84.58, 'Test Time': 4.6096789836883545}\n",
      "{'Epoch': 29, 'Train Loss': 0.005797843512892723, 'Train Accuracy': 72.54833333333333, 'Train Time': 75.34725975990295, 'Test Loss': 0.0033677549809217455, 'Test Accuracy': 84.43, 'Test Time': 4.500587224960327}\n",
      "{'Epoch': 30, 'Train Loss': 0.005765773985286554, 'Train Accuracy': 72.64333333333333, 'Train Time': 74.85412693023682, 'Test Loss': 0.0036492229133844377, 'Test Accuracy': 82.68, 'Test Time': 4.551903247833252}\n",
      "{'Epoch': 31, 'Train Loss': 0.005636464860041936, 'Train Accuracy': 73.43666666666667, 'Train Time': 75.31272768974304, 'Test Loss': 0.0032831175565719603, 'Test Accuracy': 84.98, 'Test Time': 4.46477484703064}\n",
      "{'Epoch': 32, 'Train Loss': 0.005861987238625685, 'Train Accuracy': 72.10166666666667, 'Train Time': 75.23429679870605, 'Test Loss': 0.003268213176727295, 'Test Accuracy': 84.5, 'Test Time': 4.5636374950408936}\n",
      "{'Epoch': 33, 'Train Loss': 0.005725456855694453, 'Train Accuracy': 72.84333333333333, 'Train Time': 75.5419385433197, 'Test Loss': 0.0034443146526813508, 'Test Accuracy': 83.69, 'Test Time': 4.575023651123047}\n",
      "{'Epoch': 34, 'Train Loss': 0.005622307957708836, 'Train Accuracy': 73.24, 'Train Time': 74.30643701553345, 'Test Loss': 0.003345543742179871, 'Test Accuracy': 84.13, 'Test Time': 4.54517936706543}\n",
      "{'Epoch': 35, 'Train Loss': 0.005658558320999146, 'Train Accuracy': 73.215, 'Train Time': 75.11749362945557, 'Test Loss': 0.0035404082179069517, 'Test Accuracy': 83.76, 'Test Time': 4.613462209701538}\n",
      "{'Epoch': 36, 'Train Loss': 0.005534068842232227, 'Train Accuracy': 73.73833333333333, 'Train Time': 75.48183846473694, 'Test Loss': 0.003121577903628349, 'Test Accuracy': 84.97, 'Test Time': 4.530186653137207}\n",
      "{'Epoch': 37, 'Train Loss': 0.0054514955565333366, 'Train Accuracy': 74.075, 'Train Time': 74.35168981552124, 'Test Loss': 0.0033595674157142637, 'Test Accuracy': 83.56, 'Test Time': 4.6125195026397705}\n",
      "{'Epoch': 38, 'Train Loss': 0.005631142826875051, 'Train Accuracy': 73.125, 'Train Time': 74.41995143890381, 'Test Loss': 0.0031527390271425247, 'Test Accuracy': 85.07, 'Test Time': 4.478113412857056}\n",
      "{'Epoch': 39, 'Train Loss': 0.005542110968132814, 'Train Accuracy': 73.74666666666667, 'Train Time': 74.59164929389954, 'Test Loss': 0.0033585930079221725, 'Test Accuracy': 83.65, 'Test Time': 4.578451633453369}\n",
      "{'Epoch': 40, 'Train Loss': 0.005742727398872376, 'Train Accuracy': 72.52, 'Train Time': 75.35366678237915, 'Test Loss': 0.004283814705908298, 'Test Accuracy': 81.92, 'Test Time': 4.563647985458374}\n",
      "{'Epoch': 41, 'Train Loss': 0.005696442687511444, 'Train Accuracy': 72.74666666666667, 'Train Time': 75.33990097045898, 'Test Loss': 0.003349177780747414, 'Test Accuracy': 84.05, 'Test Time': 4.580425024032593}\n",
      "{'Epoch': 42, 'Train Loss': 0.005714143919448058, 'Train Accuracy': 72.78, 'Train Time': 75.20418214797974, 'Test Loss': 0.0035136171251535417, 'Test Accuracy': 82.93, 'Test Time': 4.526031017303467}\n",
      "{'Epoch': 43, 'Train Loss': 0.005621212463080883, 'Train Accuracy': 73.24666666666667, 'Train Time': 75.38278102874756, 'Test Loss': 0.0031901735484600067, 'Test Accuracy': 84.75, 'Test Time': 4.583097219467163}\n",
      "{'Epoch': 44, 'Train Loss': 0.005377871587872505, 'Train Accuracy': 74.50833333333334, 'Train Time': 74.52018165588379, 'Test Loss': 0.0031302090659737587, 'Test Accuracy': 84.94, 'Test Time': 4.641561508178711}\n",
      "{'Epoch': 45, 'Train Loss': 0.0053408392275373145, 'Train Accuracy': 74.58, 'Train Time': 75.45503783226013, 'Test Loss': 0.00339294253885746, 'Test Accuracy': 84.08, 'Test Time': 4.539177894592285}\n",
      "{'Epoch': 46, 'Train Loss': 0.005278921791911125, 'Train Accuracy': 75.01333333333334, 'Train Time': 76.44465136528015, 'Test Loss': 0.003455298741161823, 'Test Accuracy': 84.4, 'Test Time': 4.477769136428833}\n",
      "{'Epoch': 47, 'Train Loss': 0.005118048878510793, 'Train Accuracy': 75.92333333333333, 'Train Time': 74.60856246948242, 'Test Loss': 0.002972728380560875, 'Test Accuracy': 86.04, 'Test Time': 4.569890975952148}\n",
      "{'Epoch': 48, 'Train Loss': 0.005136164376139641, 'Train Accuracy': 75.765, 'Train Time': 75.16695857048035, 'Test Loss': 0.002963074839115143, 'Test Accuracy': 86.34, 'Test Time': 4.45512056350708}\n",
      "{'Epoch': 49, 'Train Loss': 0.005123810565471649, 'Train Accuracy': 75.72833333333334, 'Train Time': 75.22738862037659, 'Test Loss': 0.0029169585451483725, 'Test Accuracy': 86.75, 'Test Time': 4.575942039489746}\n",
      "{'Epoch': 50, 'Train Loss': 0.005075040378669898, 'Train Accuracy': 75.865, 'Train Time': 75.78520679473877, 'Test Loss': 0.003180872818827629, 'Test Accuracy': 84.13, 'Test Time': 4.609530925750732}\n",
      "{'Epoch': 51, 'Train Loss': 0.005010813182592392, 'Train Accuracy': 76.17, 'Train Time': 74.33341884613037, 'Test Loss': 0.0028663993820548057, 'Test Accuracy': 86.17, 'Test Time': 4.639240503311157}\n",
      "{'Epoch': 52, 'Train Loss': 0.0050333072751760485, 'Train Accuracy': 76.22833333333334, 'Train Time': 74.2378740310669, 'Test Loss': 0.003041369642317295, 'Test Accuracy': 85.72, 'Test Time': 4.599849462509155}\n",
      "{'Epoch': 53, 'Train Loss': 0.00505640606234471, 'Train Accuracy': 75.98333333333333, 'Train Time': 74.76436233520508, 'Test Loss': 0.0028475742504000664, 'Test Accuracy': 86.79, 'Test Time': 4.601680755615234}\n",
      "{'Epoch': 54, 'Train Loss': 0.004976114586492379, 'Train Accuracy': 76.46833333333333, 'Train Time': 75.2868173122406, 'Test Loss': 0.003107043609023094, 'Test Accuracy': 84.84, 'Test Time': 4.494901418685913}\n",
      "{'Epoch': 55, 'Train Loss': 0.00499389404108127, 'Train Accuracy': 76.45833333333333, 'Train Time': 74.64643359184265, 'Test Loss': 0.002850480057299137, 'Test Accuracy': 86.85, 'Test Time': 4.495875120162964}\n",
      "{'Epoch': 56, 'Train Loss': 0.004943887481590112, 'Train Accuracy': 76.55833333333334, 'Train Time': 75.39926886558533, 'Test Loss': 0.0031890137419104576, 'Test Accuracy': 84.84, 'Test Time': 4.592783451080322}\n",
      "{'Epoch': 57, 'Train Loss': 0.004979018520812194, 'Train Accuracy': 76.49666666666667, 'Train Time': 74.54210233688354, 'Test Loss': 0.0030784569680690765, 'Test Accuracy': 84.97, 'Test Time': 4.570148229598999}\n",
      "{'Epoch': 58, 'Train Loss': 0.004928416573007901, 'Train Accuracy': 76.69833333333334, 'Train Time': 67.14748120307922, 'Test Loss': 0.0032866866797208786, 'Test Accuracy': 84.13, 'Test Time': 3.0680487155914307}\n",
      "{'Epoch': 59, 'Train Loss': 0.004926814577976862, 'Train Accuracy': 76.67666666666666, 'Train Time': 51.06670951843262, 'Test Loss': 0.0026881586030125617, 'Test Accuracy': 87.42, 'Test Time': 3.1153452396392822}\n",
      "{'Epoch': 60, 'Train Loss': 0.004865158128241698, 'Train Accuracy': 76.97333333333333, 'Train Time': 50.38881993293762, 'Test Loss': 0.0026430311769247055, 'Test Accuracy': 87.88, 'Test Time': 3.0285804271698}\n",
      "{'Epoch': 61, 'Train Loss': 0.004843242213129997, 'Train Accuracy': 77.19666666666667, 'Train Time': 51.21749544143677, 'Test Loss': 0.0034513818621635436, 'Test Accuracy': 83.86, 'Test Time': 2.8456757068634033}\n",
      "{'Epoch': 62, 'Train Loss': 0.004919524101912975, 'Train Accuracy': 76.86, 'Train Time': 49.87245535850525, 'Test Loss': 0.0026606878682971, 'Test Accuracy': 87.54, 'Test Time': 3.007758617401123}\n",
      "{'Epoch': 63, 'Train Loss': 0.004851777315139771, 'Train Accuracy': 76.84333333333333, 'Train Time': 50.254735231399536, 'Test Loss': 0.0029452590063214303, 'Test Accuracy': 86.13, 'Test Time': 3.1402628421783447}\n",
      "{'Epoch': 64, 'Train Loss': 0.004879140604039033, 'Train Accuracy': 76.90833333333333, 'Train Time': 50.56049919128418, 'Test Loss': 0.004034183186292648, 'Test Accuracy': 82.15, 'Test Time': 2.9724268913269043}\n",
      "{'Epoch': 65, 'Train Loss': 0.004857807977497577, 'Train Accuracy': 76.9, 'Train Time': 49.77454900741577, 'Test Loss': 0.0032430418148636816, 'Test Accuracy': 84.46, 'Test Time': 3.006770372390747}\n",
      "{'Epoch': 66, 'Train Loss': 0.004784349426627159, 'Train Accuracy': 77.21833333333333, 'Train Time': 50.539554834365845, 'Test Loss': 0.0032916743248701096, 'Test Accuracy': 83.89, 'Test Time': 3.0837275981903076}\n",
      "{'Epoch': 67, 'Train Loss': 0.004814508952200413, 'Train Accuracy': 77.13, 'Train Time': 50.58655619621277, 'Test Loss': 0.002954693992435932, 'Test Accuracy': 85.72, 'Test Time': 3.1083881855010986}\n",
      "{'Epoch': 68, 'Train Loss': 0.004784232752025127, 'Train Accuracy': 77.29666666666667, 'Train Time': 51.46830892562866, 'Test Loss': 0.0029517186760902405, 'Test Accuracy': 85.98, 'Test Time': 3.09309720993042}\n",
      "{'Epoch': 69, 'Train Loss': 0.0048031652768452966, 'Train Accuracy': 77.23666666666666, 'Train Time': 49.936197996139526, 'Test Loss': 0.0030146119579672814, 'Test Accuracy': 85.46, 'Test Time': 3.0255627632141113}\n",
      "{'Epoch': 70, 'Train Loss': 0.00480740647961696, 'Train Accuracy': 77.18333333333334, 'Train Time': 50.12154579162598, 'Test Loss': 0.003220220908522606, 'Test Accuracy': 84.95, 'Test Time': 3.077392101287842}\n",
      "{'Epoch': 71, 'Train Loss': 0.004770107790331045, 'Train Accuracy': 77.44833333333334, 'Train Time': 49.742106199264526, 'Test Loss': 0.0031888864174485208, 'Test Accuracy': 85.17, 'Test Time': 2.861589193344116}\n",
      "{'Epoch': 72, 'Train Loss': 0.0047859331871072455, 'Train Accuracy': 77.35666666666667, 'Train Time': 49.39428353309631, 'Test Loss': 0.002915574453771114, 'Test Accuracy': 86.41, 'Test Time': 3.0374526977539062}\n",
      "{'Epoch': 73, 'Train Loss': 0.00479086746921142, 'Train Accuracy': 77.30166666666666, 'Train Time': 50.641053438186646, 'Test Loss': 0.0029793243780732153, 'Test Accuracy': 85.94, 'Test Time': 3.0367870330810547}\n",
      "{'Epoch': 74, 'Train Loss': 0.004701125445961952, 'Train Accuracy': 77.685, 'Train Time': 51.039140462875366, 'Test Loss': 0.0030852742090821264, 'Test Accuracy': 85.62, 'Test Time': 3.037945032119751}\n",
      "{'Epoch': 75, 'Train Loss': 0.004745787377158801, 'Train Accuracy': 77.63166666666666, 'Train Time': 50.36626601219177, 'Test Loss': 0.00275885818451643, 'Test Accuracy': 86.87, 'Test Time': 3.0132548809051514}\n",
      "{'Epoch': 76, 'Train Loss': 0.004760584536194801, 'Train Accuracy': 77.37833333333333, 'Train Time': 49.751526832580566, 'Test Loss': 0.002723886503279209, 'Test Accuracy': 86.63, 'Test Time': 3.0203449726104736}\n",
      "{'Epoch': 77, 'Train Loss': 0.004744620317717393, 'Train Accuracy': 77.46, 'Train Time': 49.97594356536865, 'Test Loss': 0.002645990306138992, 'Test Accuracy': 87.41, 'Test Time': 3.0426721572875977}\n",
      "{'Epoch': 78, 'Train Loss': 0.0047165155579646425, 'Train Accuracy': 77.80666666666667, 'Train Time': 49.73059940338135, 'Test Loss': 0.0025388448044657706, 'Test Accuracy': 87.99, 'Test Time': 2.998230457305908}\n",
      "{'Epoch': 79, 'Train Loss': 0.004660787254571914, 'Train Accuracy': 78.0, 'Train Time': 49.73428416252136, 'Test Loss': 0.0027331030592322348, 'Test Accuracy': 86.96, 'Test Time': 3.0461127758026123}\n",
      "{'Epoch': 80, 'Train Loss': 0.004680219832559427, 'Train Accuracy': 78.00333333333333, 'Train Time': 50.86822772026062, 'Test Loss': 0.0032571658030152322, 'Test Accuracy': 85.05, 'Test Time': 3.009915828704834}\n",
      "{'Epoch': 81, 'Train Loss': 0.00467651666055123, 'Train Accuracy': 77.785, 'Train Time': 50.569138050079346, 'Test Loss': 0.0028638844773173334, 'Test Accuracy': 86.28, 'Test Time': 2.963289976119995}\n",
      "{'Epoch': 82, 'Train Loss': 0.0046511905113856, 'Train Accuracy': 78.11, 'Train Time': 50.25322723388672, 'Test Loss': 0.0024495476141571998, 'Test Accuracy': 88.57, 'Test Time': 3.014641284942627}\n",
      "{'Epoch': 83, 'Train Loss': 0.004629370421171188, 'Train Accuracy': 78.165, 'Train Time': 49.991666316986084, 'Test Loss': 0.002561560097336769, 'Test Accuracy': 87.96, 'Test Time': 3.071274518966675}\n",
      "{'Epoch': 84, 'Train Loss': 0.00464226846943299, 'Train Accuracy': 78.02166666666666, 'Train Time': 50.308934688568115, 'Test Loss': 0.002780691356956959, 'Test Accuracy': 86.91, 'Test Time': 3.0303127765655518}\n",
      "{'Epoch': 85, 'Train Loss': 0.004626271031796933, 'Train Accuracy': 77.985, 'Train Time': 49.794692277908325, 'Test Loss': 0.0027266304180026055, 'Test Accuracy': 87.15, 'Test Time': 3.051863431930542}\n",
      "{'Epoch': 86, 'Train Loss': 0.004651154100398223, 'Train Accuracy': 78.025, 'Train Time': 42.803890228271484, 'Test Loss': 0.002701044887304306, 'Test Accuracy': 87.31, 'Test Time': 2.1344940662384033}\n",
      "{'Epoch': 87, 'Train Loss': 0.00463315089593331, 'Train Accuracy': 78.26666666666667, 'Train Time': 35.331480503082275, 'Test Loss': 0.0028392719745635986, 'Test Accuracy': 86.81, 'Test Time': 1.950237512588501}\n",
      "{'Epoch': 88, 'Train Loss': 0.004608569620052973, 'Train Accuracy': 78.15333333333334, 'Train Time': 35.69945168495178, 'Test Loss': 0.0030030199125409126, 'Test Accuracy': 85.91, 'Test Time': 2.068808078765869}\n",
      "{'Epoch': 89, 'Train Loss': 0.004630597410599391, 'Train Accuracy': 78.025, 'Train Time': 35.621347188949585, 'Test Loss': 0.0028003576561808586, 'Test Accuracy': 86.85, 'Test Time': 2.0107743740081787}\n",
      "{'Epoch': 90, 'Train Loss': 0.004569934628903866, 'Train Accuracy': 78.40166666666667, 'Train Time': 35.733688831329346, 'Test Loss': 0.002620827230811119, 'Test Accuracy': 87.15, 'Test Time': 1.9521167278289795}\n",
      "{'Epoch': 91, 'Train Loss': 0.004608916701873143, 'Train Accuracy': 78.07666666666667, 'Train Time': 34.71537804603577, 'Test Loss': 0.002593327844142914, 'Test Accuracy': 87.62, 'Test Time': 2.009324312210083}\n",
      "{'Epoch': 92, 'Train Loss': 0.004600830768048764, 'Train Accuracy': 78.26166666666667, 'Train Time': 35.9295015335083, 'Test Loss': 0.0033316663026809693, 'Test Accuracy': 84.91, 'Test Time': 2.1586132049560547}\n",
      "{'Epoch': 93, 'Train Loss': 0.004557164058089256, 'Train Accuracy': 78.28166666666667, 'Train Time': 36.10461187362671, 'Test Loss': 0.0025301605224609374, 'Test Accuracy': 87.73, 'Test Time': 1.9609425067901611}\n",
      "{'Epoch': 94, 'Train Loss': 0.004577727138002714, 'Train Accuracy': 78.31833333333333, 'Train Time': 34.58274006843567, 'Test Loss': 0.002847193941473961, 'Test Accuracy': 86.3, 'Test Time': 1.9527556896209717}\n",
      "{'Epoch': 95, 'Train Loss': 0.00455558954924345, 'Train Accuracy': 78.54666666666667, 'Train Time': 34.366912603378296, 'Test Loss': 0.0026514892488718033, 'Test Accuracy': 87.95, 'Test Time': 1.8801872730255127}\n",
      "{'Epoch': 96, 'Train Loss': 0.0045423839896917345, 'Train Accuracy': 78.65333333333334, 'Train Time': 35.01960825920105, 'Test Loss': 0.0029118161112070082, 'Test Accuracy': 85.27, 'Test Time': 2.074862480163574}\n",
      "{'Epoch': 97, 'Train Loss': 0.0045729455629984535, 'Train Accuracy': 78.32833333333333, 'Train Time': 35.052371978759766, 'Test Loss': 0.002423192873597145, 'Test Accuracy': 88.77, 'Test Time': 1.9729173183441162}\n",
      "{'Epoch': 98, 'Train Loss': 0.0045622271011273065, 'Train Accuracy': 78.42, 'Train Time': 35.65555453300476, 'Test Loss': 0.0024689163222908973, 'Test Accuracy': 88.38, 'Test Time': 1.9121894836425781}\n",
      "{'Epoch': 99, 'Train Loss': 0.0045667237237095835, 'Train Accuracy': 78.43333333333334, 'Train Time': 34.67370867729187, 'Test Loss': 0.002689848206937313, 'Test Accuracy': 86.94, 'Test Time': 2.0926105976104736}\n",
      "{'Epoch': 100, 'Train Loss': 0.0044922748963038125, 'Train Accuracy': 78.735, 'Train Time': 35.50686526298523, 'Test Loss': 0.0028034562915563582, 'Test Accuracy': 86.27, 'Test Time': 1.9553942680358887}\n"
     ]
    }
   ],
   "source": [
    "# Data_List = [\"CIFAR10\", \"CIFAR100\", \"IMAGENET\", \"MNIST\", \"FASION_MNIST\", \"PascalVOC\", \"Flowers102\"]\n",
    "Data_List = [\"FASION_MNIST\"]\n",
    "\n",
    "for DATA in Data_List:\n",
    "    trainloader, testloader, num_classes = LoadData(DATA, 128)\n",
    "\n",
    "    model = ResNet50(num_classes, 1).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "    landaparam = 1e-3\n",
    "\n",
    "    last_epoch = 0\n",
    "    num_epochs = 100\n",
    "    history = []\n",
    "\n",
    "    for epoch in range(last_epoch,num_epochs):\n",
    "        t0 = time()\n",
    "        model.train(True)\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        train_loss, train_accuracy = train(model, trainloader, criterion, optimizer, landaparam)\n",
    "        t1 = time()\n",
    "        test_loss, test_accuracy = test(model, testloader, criterion, landaparam)\n",
    "        t2 = time()\n",
    "\n",
    "        data = {\n",
    "            \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Train Accuracy\": train_accuracy,\n",
    "            \"Train Time\": t1 - t0,\n",
    "            \"Test Loss\": test_loss,\n",
    "            \"Test Accuracy\": test_accuracy,\n",
    "            \"Test Time\": t2 - t1,\n",
    "        }\n",
    "        print(data)\n",
    "        history.append(data)\n",
    "\n",
    "    pd.DataFrame(history).to_json(f'./History/{DATA}-Neuron-Loss-new.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR10-ResNet50_85%.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
